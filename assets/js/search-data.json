{
  
    
        "post0": {
            "title": "[Filebeat] Dataflow, Filebeat to Kafka Cluster",
            "content": "파일비츠-카프카 데이터 파이프라인 구축 . . yml 파일 수정 . yml 파일 수정을 통해 카프카 클러스터로 데이터 전송을 진행해보겠습니다. . | filebeat.yml 파일을 수정하는 방식으로 진행하겠습니다. . | vim filebeat.yml 한 후 아래 내용을 파일의 적당한 위치에 추가해줍니다.(저 같은 경우 파일 제일 끝에 추가하였습니다) . | . output.kafka: hosts: [&quot;59.23.xxx.xxx:{port}&quot;,&quot;59.23.xxx.xxx:{port}&quot;] topics: &quot;{topic-name}&quot; partition.round_robin: reachable_only: false required_acks: 1 compression: gzip max_message_bytes: 1000000 . 실행 방법 : ./filebeat -e | . . 클러스터 IP 및 Port . 두 개 이상의 카프카를 이용하면 hosts의 대괄호 안쪽에 콤마를 이용해 계속 추가해나가면 됩니다. . | 포트의 경우 카프카에서 리스너의 기본 포트인 9092를 사용하거나 포트포워딩을 진행했다면 포트포워드한 포트를 {port} 자리에 대체하면 됩니다. . | .",
            "url": "https://knu-cd2.github.io/blog/filebeat/2022/05/27/filebeat-to-kafka.html",
            "relUrl": "/filebeat/2022/05/27/filebeat-to-kafka.html",
            "date": " • May 27, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "[Filebeat] Filebeat Download and Setting",
            "content": "파일비츠 다운로드 및 설치 . 파일 비츠를 다운로드하고 실행해보는 과정입니다. . . 파일비츠 다운로드 . 본인 환경에 맞게 다운로드를 진행하면 됩니다. 저같은 경우 라즈베리파이4를 이용했기에 arm64(aarch64)로 진행했습니다. | . wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.1.0-linux-arm64.tar.gz . wget을 이용해 파일비츠를 다운로드 합니다 | . tar -zxvf filebeat-8.1.0-linux-arm64.tar.gz . tar를 이용해 압축을 풀어줍니다. | . . filebeats.yml 설정 . 압축을 푼 파일비츠 폴더로 이동해 vim test.yml, test 이름을 가진 .yml 파일을 작성합니다. . | test.yml 파일은 아래와 같은 내용으로 작성합니다. . | . filebeat.inputs: - type: log enabled: true paths: - /home/{유저 홈디렉토리 명}/test/*.log output.console: enabled: true . test 폴더에는 Hello Beats!가 적힌 test.log 파일이 들어있습니다. . | yml을 작성 완료한 후에 ./filebeat -c test.yml -e 로 실행시켜줍니다. . | . . 위와 같이 Hello Beats! 가 메세지로 나타나는 것을 확인 할 수 있습니다. | . . filebeat 실행시 옵션에 대해서 . -e 옵션은 에러 로그를 콘솔에 보여줍니다.(좀 더 정확하게는 stderr) . | -c {yml 파일명}은 파일비츠를 실행시킬 yml 파일을 지정할 수 있습니다. 만약 지정하지 않는다면 filebeat.yml 파일이 default로 지정됩니다. . | .",
            "url": "https://knu-cd2.github.io/blog/filebeat/2022/05/26/filebeat-download.html",
            "relUrl": "/filebeat/2022/05/26/filebeat-download.html",
            "date": " • May 26, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "[Logstash] Dataflow, Kafka Cluster to Logstash",
            "content": "카프카-로그스태시 데이터 파이프라인 구축 . 카프카 클러스터로부터 로그스태시를 이용해 데이터를 가져오는 방법 . . logstash에서 conf 파일 설정 . 사용할 conf 파일의 input 부분을 아래와 같이 구성하면 간단하게 완료됩니다. | . input { kafka { bootstrap_servers =&gt; &quot;59.23.xxx.xxx:{port},59.23.xxx.xxx:{port}&quot; topics =&gt; [&quot;{topic name}&quot;] consumer_threads =&gt; 1 } } . 클러스터를 구성한 경우 bootstrap_servers에 모든 IP:PORT를 적어주면 됩니다. . | 여기서 주의할 점은 하나의 &quot;&quot; 안에 적어주어야 합니다. 아래와 같이 작성하면 오류가 발생합니다. . | . (error case1) bootstrap_servers =&gt; &quot;59.23.xxx.xxx:{port}&quot;, &quot;59.23.xxx.xxx:{port}&quot; (error case2) bootstrap_servers =&gt; [&quot;59.23.xxx.xxx:{port}&quot;, &quot;59.23.xxx.xxx:{port}&quot;] . 이 외에도 데이터를 불러올 때 다양한 옵션들이 많습니다. 다양한 옵션들은 logstash 공식 문서에서 확인하실 수 있습니다. | .",
            "url": "https://knu-cd2.github.io/blog/logstash/2022/05/24/kafka-to-logstash.html",
            "relUrl": "/logstash/2022/05/24/kafka-to-logstash.html",
            "date": " • May 24, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "[Elasticsearch] Elasticsearch Python Client Connecting",
            "content": "파이썬 엘라스틱서치 클라이언트 . 파이썬에서 엘라스틱서치 클라이언트를 사용하는 방법을 알아보겠습니다. . . 라이브러리 설치 . pip install elasticsearch . pip 명령어를 이용해 엘라스틱서치 라이브러리를 다운로드 받습니다. | . . 파이썬 연결 확인 . from elasticsearch import Elasticsearch # Password for the &#39;elastic&#39; user generated by Elasticsearch ELASTIC_PASSWORD = &quot;yourpassword&quot; # Create the client instance client = Elasticsearch( &quot;https://localhost:9200&quot;, ca_certs=&quot;/Users/squareyun/Documents/utility/elasticsearch-8.1.0/config/certs/http_ca.crt&quot;, basic_auth=(&quot;elastic&quot;, ELASTIC_PASSWORD) ) # Successful response! print(client.info()) # {&#39;name&#39;: &#39;instance-0000000000&#39;, &#39;cluster_name&#39;: ...} . 위와 동일하게 py 파일을 작성하여 실행시켜 보세요. | ca_certs에서 http 인증서가 있는 경로를 올바르게 작성해야 합니다. | . 실행 결과 . . . 에러 종류 . No such file or directory . lastic_transport.TlsError: TLS error caused by: TlsError(TLS error caused by: SSLError([Errno 2] No such file or directory)) . ca_certs에 입력한 인증서 경로가 잘못되었다는 에러입니다. | 파일 위치를 다시 확인해주시고, 특히 윈도우 환경에서는 경로 작성에 유의하세요. | . . self signed certificate in certificate chain . curl: (60) SSL certificate problem: self signed certificate in certificate chain . 저의 경우는 인증서에 문제가 있을 때 발생하였습니다. | 정확한 인증서가 맞는지 재확인 해주시고, 인증서 파일이 없다면 이 페이지를 통해 인증서를 발급하세요. | . . ⚠️ 서버가 외부에 있는 경우 ⚠️ . 엘라스틱서치 서버가 외부에 있는 경우 인증서 파일을 연결해도 실행이 되지 않습니다. | 외부 클라이언트에서 엘라스틱서치 서버로 접근할 때 http.p12 인증서가 기관이 인증하지 않은 인증서이므로 외부에서는 신뢰할 수 없습니다. | 외부 클라이언트에서 접근하기 위해서는 서버 IP를 DNS로 등록, 도메인 정보가 포함되어있는 CA인증서가 필요합니다. | 추가적인 설명은 이 블로그를 참고하세요. | . . 인덱스 생성 및 조회 . from datetime import datetime from elasticsearch import Elasticsearch ELASTIC_PASSWORD = &quot;yourpassword&quot; client = Elasticsearch( &quot;https://localhost:9200&quot;, ca_certs=&quot;/Users/squareyun/Documents/utility/elasticsearch-8.1.0/config/certs/http_ca.crt&quot;, basic_auth=(&quot;elastic&quot;, ELASTIC_PASSWORD) ) # doc 객체 생성 doc = { &#39;author&#39;: &#39;kimchy&#39;, &#39;text&#39;: &#39;Elasticsearch: cool. bonsai cool.&#39;, &#39;timestamp&#39;: datetime.now(), } # 인덱스 생성 resp = client.index(index=&quot;test-index&quot;, id=1, document=doc) print(resp[&#39;result&#39;]) # 인덱스 조회 resp = client.get(index=&quot;test-index&quot;, id=1) print(resp[&#39;_source&#39;]) client.indices.refresh(index=&quot;test-index&quot;) resp = client.search(index=&quot;test-index&quot;, query={&quot;match_all&quot;: {}}) print(&quot;Got %d Hits:&quot; % resp[&#39;hits&#39;][&#39;total&#39;][&#39;value&#39;]) for hit in resp[&#39;hits&#39;][&#39;hits&#39;]: print(&quot;%(timestamp)s %(author)s: %(text)s&quot; % hit[&quot;_source&quot;]) . 인덱스를 생성하고 조회하는 예제입니다. | document를 생성할 때 시간 정보를 넣기 위해 datetime 라이브러리를 사용합니다. | . 실행 결과 . . . 더 읽을거리 . https://www.elastic.co/guide/en/elasticsearch/client/python-api/8.2/connecting.html | https://elasticsearch-py.readthedocs.io/en/v8.2.0/ | https://www.lesstif.com/gitbook/https-ssl-curl-web-browser-16744456.html | .",
            "url": "https://knu-cd2.github.io/blog/elasticsearch/2022/05/20/elasticsearch-python.html",
            "relUrl": "/elasticsearch/2022/05/20/elasticsearch-python.html",
            "date": " • May 20, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "[Kafka] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)",
            "content": "카프카 실행 에러 . . 에러 로그 . ERROR Exiting Kafka due to fatal exception (kafka.Kafka$) java.nio.file.NoSuchFileException: - at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) at java.nio.file.Files.newByteChannel(Files.java:361) at java.nio.file.Files.newByteChannel(Files.java:407) at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384) at java.nio.file.Files.newInputStream(Files.java:152) at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:668) at kafka.Kafka$.getPropsFromArgs(Kafka.scala:52) at kafka.Kafka$.main(Kafka.scala:86) at kafka.Kafka.main(Kafka.scala) . 카프카를 실행 했을 때 위와 같은 오류가 뜨면서 실행이 되지 않았습니다. . . . 에러 당시 상황 . 카프카를 단일 노드로 실행하고 테스트하다가 클러스터를 구성해서 실행하니깐 저런 에러가 뜬 것으로 예측됩니다. . . 해결 방법 . . 해당 방법이 정확한 방법이 아닐 수 있습니다 before . . after . . 저같은 경우 카프카 폴더 안 config 폴더에 들어있는 server.properties 파일에서 log.dirs 옵션을 log.dir로 바꿔서 실행하니 해결이 되었습니다. .",
            "url": "https://knu-cd2.github.io/blog/kafka/2022/05/19/kafka-error1.html",
            "relUrl": "/kafka/2022/05/19/kafka-error1.html",
            "date": " • May 19, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "[Kafka] Deploy Kafka Cluster",
            "content": "카프카 클러스터 구성하기 . 라즈베리파이에 올라간 카프카의 클러스터를 구성하는 방법입니다. . . zookeeper 설정 및 실행 . cd kafka vim config/zookeeper.properties . 위 커맨드를 입력해서 zookeeper 설정 파일을 열어줍니다.그리고 클러스터를 구성할 정보를 입력해줍니다. . initLimit=5 syncLimit=2 server.1={IP 주소}:2888:3888 server.2={IP 주소}:2888:3888 server.3={IP 주소}:2888:3888 . 저 같은 경우 라즈베리파이가 공유기 하나에 연결되어 있어서 내부 IP로 진행하였습니다. 위 사진에선 컴퓨터 한대에서만 설정한 것 처럼 보이는데 모든 컴퓨터에 다 설정해주어야 합니다. . . 1번 컴퓨터에서 echo 1 &gt; /tmp/zookeeper/myid 2번 컴퓨터에서 echo 2 &gt; /tmp/zookeeper/myid 3번 컴퓨터에서 echo 3 &gt; /tmp/zookeeper/myid . 그 다음 dataDir의 경로에 해당 클러스터가 몇 번 클러스터인지 설정해줍니다. 만약 tmp나 zookeeper 폴더가 없다면 mkdir 커맨드로 생성해주도록 합니다. 그리고 myid는 겹쳐서는 안됩니다. . 이렇게 하면 zookeeper 관련해서 클러스터 설정은 끝입니다. . . 주키퍼 실행 bin/zookeeper-server-start.sh -daemon config/zookeeper.properties . 마지막으로 모든 컴퓨터에 해당 커맨드를 입력하여 zookeeper를 실행시켜 줍니다. -daemon 옵션을 주면 백그라운드로 실행하게 됩니다. . 종료는 bin/zookeeper-server-stop.sh 커맨드를 날려서 종료하면 됩니다. . . Kafka 설정 및 실행 . . 카프카 실행 시 에러가 나면 아래 링크를 참조해주세요 ERROR Exiting Kafka due to fatal exception (kafka.Kafka$) . . vim config/server.properties . 위 커맨드를 입력하여 카프카와 관련된 설정파일을 열어줍니다. . broker.id 옵션을 찾아서 zookeeper에서 설정한 myid 값을 넘겨줍니다. . . advertised.listeners 옵션을 찾아서 listen할 아이피와 포트를 설정해주도록 합니다. 일단은 외부와의 통신을 고려하지 않고 진행하기 때문에 위와 같이 설정하였습니다. 저 같은 경우 listeners 옵션 주석이 풀려있는데 이 옵션은 주석을 풀지 않고 그대로 두셔도 됩니다. . . 마지막으로 zookeeper.connect에 zookeeper에서 클러스터를 구성한 노드(컴퓨터)들의 IP 주소와 포트를 적어줍니다. . 카프카 실행 bin/kafka-server-start.sh -daemon config/server.properties . 그리고 모든 컴퓨터에서 카프카를 실행을 시켜줍니다. . 종료하는 방법은 bin/kafka-server-stop.sh 커맨드를 날려서 종료해주면 됩니다. . . 클러스터가 정상적으로 실행되는지 확인하기 위해 토픽을 생성하고 토픽 리스트를 보는 테스트를 해보겠습니다. . 토픽생성 bin/kafka-topics.sh --create --bootstrap-server 192.168.0.11:9092,192.168.0.12:9092,192.168.0.13:9092 --replication-factor 3 --partitions 3 --topic cluster-test 토픽 리스트 확인 bin/kafka-topics.sh --list --bootstrap-server 192.168.0.11:9092,192.168.0.12:9092,192.168.0.13:9092 . 위와 같이 cluster-test 이름을 가진 토픽이 생성되고 리스트에서 확인할 수 있는 것을 볼 수 있습니다. . . . 카프카 클러스터를 외부에서 컨트롤 할 경우 . 제 노트북의 윈도우 WSL(외부환경)에서 카프카 클러스터에 토픽 생성 등과 같이 컨트롤이 필요할 경우 설정에 대해 알려드리겠습니다. . vim config/server.properties . 위 파일을 다시 연 다음에 listen을 담당하는 advertised.listeners 부분만 변경해주면 됩니다. . advertised.listeners=PLAINTEXT://{외부 IP}:{외부 포트} . 저 같은 경우 각각 외부에서 30011, 30012, 30013으로 설정하였습니다. . . 그 후 포트포워딩도 진행하였습니다. 포트포워딩을 위해 추가한 설정은 순위 13~15 입니다. . . . 로컬에서 테스트 . 마지막으로 제 노트북의 WSL환경에서 카프카 클러스터와 통신이 가능한지 테스트해보겠습니다. (테스트하기 위해서는 WSL환경에 자바와 카프카가 설치되어 있어야합니다.) . bin/kafka-topic.sh --list --bootstrap-server {외부IP}:{외부 포트},{외부IP}:{외부 포트},{외부IP}:{외부 포트} . 토픽 리스트를 확인하는 커맨드를 날려주면 정상적으로 통신을 해 토픽 리스트들을 받아온 것을 확인 할 수 있습니다. . . .",
            "url": "https://knu-cd2.github.io/blog/kafka/2022/05/19/kafka-cluster.html",
            "relUrl": "/kafka/2022/05/19/kafka-cluster.html",
            "date": " • May 19, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "SSH connect with vscode",
            "content": "서론 . 원격 서버에 접속하여 사용할 때 파일 시스템을 한눈에 보고 싶을 때나, vim 명령어가 익숙하지 않아 불편할 때가 있습니다. . 그럴 때 vscode의 원격 접속 확장 프로그램을 사용하면 편리하게 서버에 접속할 수 있습니다. . 확장 프로그램 설치 . . vscode가 설치되어 있지 않다면 공식 사이트에서 다운로드하세요. vscode를 실행시키고, 좌측 메뉴바에서 마켓플레이스에 들어가 SSH를 검색합니다. . . 위 사진에 해당하는 확장 프로그램을 설치해주세요. . 원격 접속 세팅 . 설치 후 vscode 화면의 좌측 하단의 &gt; &lt; 버튼을 클릭하세요. . . . Connect to Host… &gt; Configure SSH Hosts… &gt; {save points} 순으로 선택하여 config 파일을 생성하고 작성합니다. . Host test_server HostName xxx.xxx.xxx.xxx User test_user Port xxxx . Host는 서버 정보 이름을 무엇으로 정할지 나타내는 것이고, HostName, User, Port는 접속할 원격 서버 정보를 작성합니다. . 작성을 완료 하셨으면 다시 버튼을 클릭하여 아까 저장해둔 정보로 접속을 해봅시다. . . 서버의 비밀번호를 작성하면 접속에 성공합니다 ! . 비밀번호 작성하는 것이 귀찮아졌다면, 원격 접속 자동 로그인 게시글을 참고해주세요. .",
            "url": "https://knu-cd2.github.io/blog/ssh/2022/05/16/vscode-ssh.html",
            "relUrl": "/ssh/2022/05/16/vscode-ssh.html",
            "date": " • May 16, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "SSH connect auto login with vscode",
            "content": "서론 . vscode를 이용하여 원격 접속할 때 비밀번호를 매번 입력하는 과정이 귀찮습니다. . 꼭 vscode를 이용할 때 뿐만 아니라 shell에서 접속할 때도 마찬가지입니다. . 원격 접속을 할 때 비밀번호를 입력하지 않고 자동으로 인증되도록 설정하는 방법을 알아보겠습니다. . SSH key 생성하기 . SSH key는 공개 키 (Public Key)와 비공개 키 (Private Key)로 이루어져 있습니다. . 비공개 키 id_rsa는 로컬 컴퓨터에 존재해야하며, 공개 키 id_rsa.pub는 원격 서버에 존재해야합니다. . 비공개 키는 외부에 절대로 노출되어서는 안됩니다. . SSH key를 생성하고 공개 키를 원격 서버에 저장하는 과정을 알아보겠습니다. . SSH key 생성 . . windows는 git bash를 이용하여 진행하면 동일하게 진행할 수 있습니다. 우선 SSH key가 이미 존재하는지 확인해봅시다. . cat ~/.ssh/id_rsa.pub . ssh-rsa로 시작하는 문자열이 출력된다면 다음 단계로 진행하세요. . 없다면 다음을 명령어로 키를 생성합니다. . ssh-keygen -t rsa . 생성할 때 모두 default로 설정하여도 좋습니다. 따로 입력하지 않고 Enter를 3번 눌러 진행하세요. . 원격 서버에 저장 . ssh-key가 생성되었다면 출력해보세요. . cat ~/.ssh/id_rsa.pub . ssh-rsa로 시작하는 문자열을 복사하여 원격 서버의 ~/.ssh/authorized_keys에 등록하도록 하겠습니다. . vi ~/.ssh/authorized_keys . 여기에 아까 복사한 ssh-rsa 문자열을 붙여넣고 저장합니다. . vscode config 파일 수정 . 이제, vscode에서 이 키를 가지고 인증하도록 세팅해주기만 하면 됩니다. . 다음과 같이 접속 config 파일을 수정하세요. . Host test_server HostName xxx.xxx.xxx.xxx User test_user Port xxxx IdentityFile ~/.ssh/id_rsa . Done! . 이제 비밀번호 없이 원격 접속이 가능합니다. .",
            "url": "https://knu-cd2.github.io/blog/ssh/2022/05/16/vscode-ssh-without-password.html",
            "relUrl": "/ssh/2022/05/16/vscode-ssh-without-password.html",
            "date": " • May 16, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "[Elasticsearch] Using curl with ElasticSearch",
            "content": "ElasticSearch에서 curl 사용하기 . Elasticsearch는 REST API를 사용하기 때문에 curl을 이용해서 간편하게 데이터를 조회하고, 추가하거나 삭제할 수 있습니다. 간단한 사용 예시를 보여드리겠습니다. . 1. curl 에러 . curl localhost:9200 . 이 커맨드를 실행하면 클러스터의 상태 정보를 알 수 있습니다. 먼저 이 커맨드를 콘솔에 입력해보겠습니다. . . Elasticsearch가 실행 중이지 않으면 Connection refuesed 에러가 발생하므로 Elasticsearch를 꼭 가동해주세요. . 다시 Elasticsearch가 가동 중인 커맨드를 입력하겠습니다. . . 이번에는 Empty reply from server 라며 클러스터의 상태정보를 알려주지 않습니다. . Elasticsearch 버전 7에서는 이러한 커맨드로 확인이 가능했지만, 버전 8이 되면서 보안설정이 생겨 단순한 curl 커맨드로는 Elasticsearch에 접근할 수 없습니다. . 2. ID, Password를 이용한 curl . 이번에는 Elasticsearch의 ID와 Password가 추가된 curl을 입력하겠습니다. . curl -u &quot;elastic:changeme&quot; -k https://localhost:9200 . ID: elastic Password: changeme ID와 Password는 사용 중인 ID와 Password를 입력하셔야 합니다. . . 아까와는 다르게 클러스터의 상태를 조회할 수 있습니다. . 3. http_ca.crt 인증서를 이용한 curl . 인증서와 Elasticsearch의 ID와 Password를 추가해 curl을 이용할 수 있습니다. . curl --cacert /home/c2-kafka/elastic/elasticsearch-8.1.0/config/certs/http_ca.crt -u &quot;elastic:kibana&quot; -X GET https://localhost:9200 . curl 커맨드 중간에 http_ca.crt의 경로를 입력해야 합니다. http_ca.crt의 상대경로가 아닌 절대경로를 입력하시면 됩니다. . . 이 커맨드 또한 아까 전과 같은 클러스터의 상태 정보를 알아낼 수 있습니다. .",
            "url": "https://knu-cd2.github.io/blog/elasticsearch/2022/05/16/about-curl.html",
            "relUrl": "/elasticsearch/2022/05/16/about-curl.html",
            "date": " • May 16, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "[Elasticsearch & Kibana] Reset ElasticSearch Token and Kibana Password",
            "content": "ElasticSearch Toekn, Password 초기화하기 . Elasticsearch 첫 화면에서 토큰 또는 비밀번호를 분실하시는 경우가 있을 수 있습니다. Elasticsearch와 Kibana를 삭제 후 재설치 하시면 토큰과 비밀번호를 재발급 받으실 수 있습니다. . 하지만 이러한 방법은 너무 번거롭기에, 삭제하지 않고 토큰과 비밀번호를 재발급 받을 수 있는 방법을 알려드리겠습니다. . 1. ElasticSearch 토큰 초기화하기 . 먼저 Elasticsearch를 실행시켜야 합니다. 그리고 Elasticsearch 폴더의 bin 폴더로 가서 . ./elasticsearch-create-enrollment-token -s kibana . 위의 커맨드를 실행시키면 됩니다. . . 그러면 사진과 같이 토큰이 초기화됩니다. . 이 토큰을 Kibana 초기 접속화면에 입력하시면 키바나 사용이 가능합니다. . 2. Kibana 비밀번호 초기화하기 . Kibana의 비밀번호를 분실하실 때도 Elasticsearch를 실행시키고, Elasticserach 폴더의 bin 폴더로 가서 . /elasticsearch-reset-password -u elastic . 위의 커맨드를 실행시키면 . . 사진과 같이 터미널에 비밀번호를 출력할 것인지 묻습니다. 그냥 y를 입력하면 . . 터미널에 비밀번호가 나타납니다. 이 비밀번호를 Kibana에 입력합니다.(초기 Username: elastic) . . Kibana 로그인이 완료되었습니다. . 비밀번호를 변경하고 싶으시면 우측상단에 프로필 창을 클릭합니다. . 사진과 같이 Kibana의 비밀번호를 원하는 비밀번호로 수정하실 수 있습니다! . 3. Elasticsearch를 실행시키지 않았을 때 . Elasticsearch를 실행시키지 않고 커맨드를 날리면 ERROR: Failed to determine the health of the cluster. 라는 에러가 발생합니다. . 그러므로 꼭 Elasticsearch를 실행시키고 커맨드를 날려주셔야 합니다. .",
            "url": "https://knu-cd2.github.io/blog/elasticsearch/kibana/2022/05/15/token-password.html",
            "relUrl": "/elasticsearch/kibana/2022/05/15/token-password.html",
            "date": " • May 15, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "[Kafka] Kafka Download and Setting",
            "content": "카프카 다운로드 및 설정 . 서버에 카프카 다운로드 후 로컬과 통신을 설정하는 과정입니다. . . 카프카 다운로드 . https://kafka.apache.org/downloads 위 사이트로 가서 카프카 다운로드 링크를 복사하도록 하겠습니다. . . . wget https://dlcdn.apache.org/kafka/3.1.0/kafka_2.13-3.1.0.tgz . 앞에 숫자는 Scalar 버전이고, 뒤에 숫자는 카프카 버전입니다. 저는 Scalar는 2.13버전, 카프카는 3.1.0 버전으로 진행하겠습니다. . . . tar -xzvf kafka_2.13-3.1.0.tgz . tar 명령어를 통해 압축을 풀어줍니다. . . . 자바 설치 . 카프카를 구동하기 위해서는 자바가 필요합니다. 자바도 설치해보도록 하겠습니다. . . sudo apt install openjdk-8-jdk-headless . 저의 경우 자바 8 버전을 설치하였습니다. . . 설치가 완료되었고 테스트 할겸 java와 javac의 버전도 출력해보았습니다. . . . 카프카 사용 메모리 설정 . 이 부분은 무료 클라우드 인스턴스를 사용하거나 온프래미스 구축시 장비의 메모리가 부족하신 분들만 진행하시면 됩니다. . vi ~/.bashrc 명령어를 사용해 배쉬쉘에 들어간 다음에 . | export KAFKA_HEAP_OPTS=&quot;-Xmx400m -Xms400m&quot; 를 입력후 저장해줍니다. . | source ./bashrc를 해준다음 echo $KAFKA_HEAP_OPTS를 입력해 환경변수가 잘 지정되었는지 확인 해줍니다. . | 저 같은 경우 메모리 8G 라즈베리파이를 이용했기에 이 과정은 넘어갔습니다. . . . server.properties 설정 . 카프카를 로컬에서 통신하기 위해 server.properties를 설정해보겠습니다. . . cd kafka_2.13-3.1.0 vim config/server.properties . . 그 다음 advertised.listeners를 찾아서 주석을 풀어주고 설정을 합니다. . 저 같은 경우 여러대의 라즈베리파이가 외부아이피 하나에 연결되어 있기에 기존의 9092포트가 아닌 30014로 설정하였습니다. 아이피 부분은 클라우드의 인스턴스나 본인이 구축한 온프레미스 환경의 외부아이피를 입력하시면 됩니다. . . 그 후 포트포워딩도 진행하였습니다. 로컬과 통신을 위해 새로 추가한 규칙은 순위 16의 규칙입니다. . . 추가적으로 카프카를 구동하기전에 server.properties 에서 log.dirs에 설정된 값에 해당하는 디렉토리가 없다면 생성해주도록 합니다. . . . 카프카 실행 . 카프카를 실행하기 위해서는 주키퍼를 실행한 다음 카프카를 실행하여야 합니다. 주키퍼의 경우 다운받은 카프카에 함께 포함되어 있습니다. . 우선 주키퍼를 실행해보도록 하겠습니다. . bin/zookeeper-server-start.sh -daemon config/zookeeper.properties . 그 다음으로 카프카를 실행해보도록 하겠습니다. . bin/kafka-server-start.sh -daemon config/server.properties . -daemon 옵션은 백그라운드로 동작하도록 해주는 옵션입니다. . 실행을 한 후에 jps를 커맨드라인에 입력하면 위와 같이 QuorumPeerMain(주키퍼) 와 Kafka가 동작 중인 것을 확인 할 수 있습니다. . . . 로컬과 카프카 통신 확인 . 저의 로컬 환경은 Window10 에서 WSL을 활용하였습니다. . WSL에서도 서버에 설치한 카프카와 자바의 버전과 동일하게 카프카와 자바를 설치해줍니다. 위에서 설치시 활용한 커맨드를 그대로 입력하면 됩니다 . . 그 후 정상적으로 통신이 가능한지 테스트를 진행합니다. . bin/kafka-broker-api-versions.sh --bootstrap-server 59.23.xxx.xxx:30014 . 통신이 정상적으로 잘 되는 것을 확인 할 수 있습니다. . . .",
            "url": "https://knu-cd2.github.io/blog/kafka/2022/05/15/kafka-download.html",
            "relUrl": "/kafka/2022/05/15/kafka-download.html",
            "date": " • May 15, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "[Logstash] PKIX path building failed error",
            "content": "문제 상황 . Logstash와 Elasticsearch를 연동하는 과정에서 다음과 같은 에러가 발생하였습니다. . . PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target . 이는 Elasticstack 8.0 버전부터 default로 보안 설정이 적용되어 생기는 문제로 보안 관련 처리를 해주어야 제대로 동작합니다. . 해결 방법 . 두 가지 방법이 있습니다. . SSL 자격 확인을 하지 않도록 설정하는 방법 | SSL 자격 인증서를 등록하는 방법 | 1번 방법에 대한 해결법은 이 게시글을 참고해주세요. . 2번 방법에 대한 해결법을 설명해드리겠습니다. . Elasticsearch 인증서 생성 . 다음 명령어를 입력하여 .cer 인증서를 생성해줍니다. . echo -n | openssl s_client -connect localhost:9200 | sed -ne &#39;/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p&#39; &gt; ./ca_logstash.cer . 생성된 파일을 ${LS_HOME}/config/certs폴더로 이동시킵니다. . conf 파일 수정 . config 파일을 다음과 같이 cacert과 ssl을 추가하여 변경합니다. . ... output { elasticsearch { index =&gt; &quot;output&quot; hosts =&gt; [&quot;https://192.168.0.6:9200&quot;, &quot;https://192.168.0.14:9200&quot;, &quot;https://192.168.0.15:9200&quot;] user =&gt; &quot;elastic&quot; password =&gt; &quot;yourpassword&quot; ssl =&gt; true cacert =&gt; &quot;/home/c1-elastic/elastic/logstash-8.1.0/config/certs/ca_logstash.cer&quot; } stdout {} } . . Elasticsearch가 다중 노드로 구성되어 있다면 hosts에 해당 노드를 모두 추가하여야 합니다. 수정 후 다시 실행하여 봅시다. . ./bin/logstash -f config/test.conf . . 사진과 같이 정상적으로 실행되었음을 확인할 수 있습니다. .",
            "url": "https://knu-cd2.github.io/blog/logstash/2022/05/14/pkix-path-building-failed.html",
            "relUrl": "/logstash/2022/05/14/pkix-path-building-failed.html",
            "date": " • May 14, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "[Logstash] How to connect Logstash with Elasticsearch",
            "content": "Logstash에서 Elasticsearch로 데이터 저장하는 방법 . 데이터 파이프라인을 구축하기 위해 Logstash에서 가공한 데이터를 Elasticsearch로 전송하여 데이터를 저장하고자 합니다. . 우선, Elasticsearch은 실행되어 있는 상태이여야 합니다. 다른 게시글을 참고하여 실행합니다. . 다음으로 config 파일 test.conf을 작성합니다. 이번 예제에서는 Elasticsearch에서 발생하는 로그를 받아와 이것을 Elasticsearch로 전송하여 인덱스 output을 생성하여 저장하고, 눈으로 확인하기 위해 표준 출력으로도 받아보겠습니다. . input { file { path =&gt; &quot;/home/c1-elastic/elastic/elasticsearch-8.1.0/logs/gc.log&quot; start_position =&gt; &quot;beginning&quot; sincedb_path =&gt; &quot;/dev/null&quot; } } output { elasticsearch { index =&gt; &quot;output&quot; hosts =&gt; [&quot;https://127.0.0.1:9200&quot;] user =&gt; &quot;elastic&quot; password =&gt; &quot;yourpassword&quot; } stdout {} } . 작성한 config 파일을 이용하여 로그스태시를 실행하여 봅시다. . ./bin/logstash -f config/test.conf . 에러 발생 . . 실행시 다음과 같은 에러가 발생합니다. . PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target . 이는 Elasticstack 8.0 버전부터 default로 보안 설정이 적용되어 생기는 문제로 보안 관련 처리를 해주어야 제대로 동작합니다. . certification 에러 해결 . 에러 해결 방법에는 두 가지 방법이 있습니다. . SSL 자격 확인을 하지 않도록 설정하는 방법 | SSL 자격 인증서를 등록하는 방법 | 여기서는 우선 1번을 이용한 해결 방법을 소개하도록 하겠습니다. . 2번 방법에 대한 해결법은 다음 게시물을 참고해주세요. . conf 파일 변경 . elasticsearch 플로그인에 다음 두 옵션 ssl_certificate_verification과 ssl을 추가합니다. . ... output { elasticsearch { index =&gt; &quot;output&quot; hosts =&gt; [&quot;https://127.0.0.1:9200&quot;] user =&gt; &quot;elastic&quot; password =&gt; &quot;yourpassword&quot; ssl_certificate_verification = false ssl = true } stdout {} } . 수정 후 다시 실행하여 봅시다. . ./bin/logstash -f config/test.conf . . 정상적으로 실행되었습니다! output에서 표준 출력으로 잘 출력되었음을 확인할 수 있습니다. . Elasticsearch에서 확인 . 실제 elasticsearch에도 인덱스가 만들어졌는지 확인해봅시다. . 다음과 같이 명령어 curl를 날려보세요. . curl -u &quot;elastic:yourpassword&quot; -k https://localhost:9200/output?pretty . . 사진과 같이 정상적으로 인덱스로 저장되었음을 확인할 수 있습니다. .",
            "url": "https://knu-cd2.github.io/blog/logstash/2022/05/14/logstash-to-elasticsearch.html",
            "relUrl": "/logstash/2022/05/14/logstash-to-elasticsearch.html",
            "date": " • May 14, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "[Elasticsearch] How to handle vm.max_map_count [65530] error in elasticsearch",
            "content": "문제 상황 . 초기 엘라스틱서치 실행 후 다음과 같이 max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 라고 오류가 발생할 때가 있습니다. . . 해결법 . 위와 같이 에러가 발생하였다면 다음과 같이 입력하여 vm.max_map_count를 262144로 변경하면 됩니다. . sudo sysctl -w vm.max_map_count=262144 . 왜 이런 에러가 발생할까? . Elasticsearch는 MMap FS라는 타입의 디렉터리를 사용하여 샤드 인덱스를 저장합니다. | 이 타입은 파일을 메모리에 매핑하여 저장하는데, 매핑되는 파일과 동일한 크기의 가상 메모리 주소 공간이 필요합니다. | 하지만, 운영 체제의 기본 제한이 너무 낮으므로 out of memory를 유발합니다. | 충분한 가상 메모리 주소 공간을 허용하라고 경고하기 때문에 이 에러가 발생한다고 알 수 있습니다. | . Reference . https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html | https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-store.html#file-system | .",
            "url": "https://knu-cd2.github.io/blog/elasticsearch/2022/05/13/vm_max_map_count_error.html",
            "relUrl": "/elasticsearch/2022/05/13/vm_max_map_count_error.html",
            "date": " • May 13, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "[Elasticsearch & Kibana] Intergrating ElasticSearch & Kibana",
            "content": "ElasticSearch와 Kibana 연동하기(8.1.0) . Elastic Stack이 7버전에서 8버전으로 바뀌면서 많은 부분이 수정되었습니다. Elasticsearch와 Kibana 연동 부분에서도 많은 변화가 있어 기존 버전 7에서의 연동방식와 차이가 있습니다. 이 글에서는 버전 8의 Elasticsearch와 Kibana 연동 방법을 설명해드리겠습니다. . 1. ElasticSearch 실행하기 . 먼저 Elasticsearch를 실행시켜는 법을 알려드리겠습니다. . 설치한 Elasticsearch 폴더 내부에 많은 파일과 폴더가 있는 걸 알 수 있습니다. Elasticsearch를 실행시킬려면 bin에 있는 elasticsearch를 실행시키면 됩니다. . ./bin/elasticsearch . . Elasticsearch를 최초로 실행시키면 이렇게 토큰과 Kibana에 접속할 비밀번호를 보여줍니다. 이를 잘 보관해두셔야 Kibana와 연동이 가능합니다. 이제 Kibana를 실행시켜 Elasticserach와 Kibana를 연동시켜 보겠습니다. . 2. Kibana 외부접속 . 로컬 컴퓨터에서 자신만 Kibana에 접속하시는 분들은 상관 없으시겠지만, Elasticsearch Stack을 사용하면 아마 Kibana에서 외부접속은 필요하실 겁니다. 외부접속을 할려면 kibana폴더 내부에 config 폴더에 kibana.yml 이 있습니다. . vi config/kibana.yml . 커맨드를 입력해서 kibana.yml 파일을 수정하겠습니다. . 초기에는 server.host: “localhost”가 주석처리 되어 있습니다. 주석을 지우고 . server.host: 0.0.0.0 . 으로 수정하시면 외부접속이 가능합니다. . 3. Kibana 실행하기 . 설치한 Kibana 폴더 내부입니다. Kibana도 bin폴더에 있는 kibana를 실행하면 됩니다. Kibana를 실행하기 전 위에서 최초로 구동시킨 Elasticsearch가 실행 중이어야 합니다. . ./bin/kibana . . 그럼 터미널에서 이렇게 코드값을 주고 Kibana가 실행됩니다. . Kibana의 port는 5601로 설정되어 있습니다. localhost:5601 또는 ServerIP:5601 로 접속하면, . 이렇게 Kibana에서 토큰을 입력하라고 합니다. 그러면 아까 Elasticsearch에서 발행된 토큰을 입력해줍니다. . 토큰이 입력되면 kibana는 코드를 입력하라 합니다. . Kibana를 실행시킬 때 코드를 입력해줍니다. . 이렇게 Elasticsearch와 Kibana의 연동이 끝납니다. . 로그인 창이 나오는데요. 초기에는 Username: elastic Password는 Elasticsearch를 최초로 실행시킬 때 나오는 password를 입력해줍니다. . 이제 Kibana에 접속이 완료되었습니다. .",
            "url": "https://knu-cd2.github.io/blog/elasticsearch/kibana/2022/05/11/intergrating-elasticsearch-and-kibana.html",
            "relUrl": "/elasticsearch/kibana/2022/05/11/intergrating-elasticsearch-and-kibana.html",
            "date": " • May 11, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "[Logstash] Download Logtash",
            "content": "리눅스 서버에 Logstash 8.1.0 설치하는 방법 . wget을 통한 Logstash 설치 . wget은 Web Get의 약어로 웹 상의 파일을 다운로드 받을 때 사용하는 리눅스 명령어로 비 상호작용 네트워크 다운로더입니다. . https://www.elastic.co/kr/downloads/past-releases/logstash-8-1-0 . 위 사이트에서 제공하는 파일을 다음과 같이 wget 명령어로 리눅스 서버에 설치합니다. . wget https://artifacts.elastic.co/downloads/logstash/logstash-8.1.0-linux-aarch64.tar.gz . . 이렇게 logstash의 압축파일을 다운로드 받았습니다. 이 파일을 압축 해제하기 위해 다음과 같이 입력합니다. . tar -zxvf logstash-8.1.0-linux-aarch64.tar.gz . . 이렇게 로그스태시 설치는 완료하였습니다. . 다음은 실행을 통해 정상적으로 설치가 완료되었는지 확인을 해 봅시다. . 실행을 통한 설치 확인 . 설치된 폴더로 이동하여 다음과 같이 명령어를 입력해봅시다. . bin/logstash -e &#39;input { stdin { } } output { stdout {} }&#39; . 이것은 input filter를 표준 입력으로, output filter를 표준 출력으로 처리하도록 하는 명령어입니다. 실행 후 Pipelines running 이라는 메세지가 뜨면 아무 문자나 입력해봅시다. . . 다음과 같이 정상적으로 설치가 되었고, 입출력되는 것을 확인하였습니다. .",
            "url": "https://knu-cd2.github.io/blog/logstash/2022/05/11/install-logstash.html",
            "relUrl": "/logstash/2022/05/11/install-logstash.html",
            "date": " • May 11, 2022"
        }
        
    
  
    
        ,"post16": {
            "title": "[Elasticsearch & Kibana] Download ElasticSearch & Kibana",
            "content": "리눅스 서버에 ElasticSearch와 Kibana 설치하기(8.1.0) . 1. ElasticSearch 설치 . https://www.elastic.co/kr/downloads/past-releases/elasticsearch-8-1-0 에 접속하시면 . 위와 같은 화면이 나옵니다. . LINUX X86_64, LINUX AARCH64 둘 중 자신의 리눅스 서버에 맞는 프로그램을 설치해야 합니다. . 설치버튼을 우클릭해서 ‘링크 주소 복사’ 클릭하고 리눅스 터미널에 . wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.1.0-linux-aarch64.tar.gz . 이렇게 입력합니다. . 그러면 사진과 같이 tar.gz파일 설치가 완료됩니다. . . 그러고 이 알집을 풀어주기 위해 . tar -zxvf elasticsearch-8.1.0-linux-aarch64.tar.gz . 커맨드를 입력합니다. . . 그러면 이렇게 elasticsearch-8.1.0 폴더가 생성되면서 ElasticSearch의 설치가 완료됩니다. . 2. Kibana 설치 . Kibana의 설치법은 ElasticSearch와 동일합니다. . https://www.elastic.co/kr/downloads/past-releases/kibana-8-1-0로 접속하시면 . 여기서도 우클릭으로 링크 주소 복사 후 리눅스 터미널에 아래 커맨드를 입력시킵니다. . wget wget https://artifacts.elastic.co/downloads/kibana/kibana-8.1.0-linux--aarch64.tar.gz . 이렇게 tar.gz 파일 설치가 완료됩니다. . 이 파일도 . tar -zxvf kibana-8.1.0-linux-aarch64.tar.gz . 커맨드를 입력해 압축을 해제합니다. . 이렇게 ElasticSearch와 Kibana의 설치가 끝났습니다. . 연동하는 방법은 다음 게시글에서 알아보도록 하겠습니다. .",
            "url": "https://knu-cd2.github.io/blog/elasticsearch/kibana/2022/05/11/install-elasticsearch-kibana.html",
            "relUrl": "/elasticsearch/kibana/2022/05/11/install-elasticsearch-kibana.html",
            "date": " • May 11, 2022"
        }
        
    
  
    
        ,"post17": {
            "title": "[On-premise] username change",
            "content": "유저 이름 바꾸기 . 서버 초기에 설치하면 유저이름이 ubuntu로 되어있습니다. 하지만 여러개의 클러스터를 운용할 때, 모든 클러스터 유저가 ubuntu로 되어 있으면 헷갈리기에 변경을 하도록 하겠습니다. . ubuntu 유저명을 바꾸는 대신 새로 유저를 생성하는 방법을 써도 됩니다. . . . . root로 ssh 접속하기 . 일반 유저로 접속 후 sudo passwd root를 입력한 후 본인이 설정하고자 하는 비밀번호를 입력합니다. 해당 커맨드는 os 처음 설치시, root 비밀번호를 설정하는 커맨드입니다. . . sudo vim /etc/ssh/sshd_config 를 입력합니다. root를 통한 ssh 접속은 기본적으로 거부되기 때문에 해당 파일의 설정을 변경해주어야 합니다. . . PermitRootLogin 속성을 찾아서 주석을 풀고 prohibit-password는 지우고 yes로 바꿔줍니다. vim을 사용하실 경우 : PermitRootLogin 을 입력하면 쉽게 찾으실 수 있습니다. . . 변경 사항을 반영하기 위해 systemctl restart sshd를 입력합니다. . . 해당 과정을 거치면 ssh를 root 계정을 통해서 접속이 가능해지게 됩니다. . . . . 사용자 이름 바꾸기 . usermod -l newname oldname 을 입력합니다 소문자 L입니다. 저의 경우 ubuntu를 simul로 바꾸어 보겠습니다. . . usermod -m -d /home/newname newname을 입력합니다. 둘 다 newname으로 적은건 오타가 아닙니다! . . 위 커맨드 입력을 실수하면 홈디렉토리가 사라질 수 있습니다. . 추가적으로 초기에 그룹 이름도 ubuntu로 되어 있는데, 그룹 이름도 바꾸고 싶은 경우 groupmod -m newname oldname 커맨드를 입력해주시면 됩니다. 저 같은 경우 이 부분은 생략하였습니다. . . . . 바뀐 사용자로 로그인 . 바뀐 사용자로 로그인 한 다음에는 이제 다시 루트 로그인을 막아야합니다. . . sudo vim /etc/ssh/sshd_config 를 입력합니다. 그 다음 PermitRootLogin 부분 주석 처리를 합니다. . . systemlctl restart sshd를 하면 정상적으로 root 로그인은 막히게 됩니다. .",
            "url": "https://knu-cd2.github.io/blog/on-premise/2022/05/10/on-premise-change-username.html",
            "relUrl": "/on-premise/2022/05/10/on-premise-change-username.html",
            "date": " • May 10, 2022"
        }
        
    
  
    
        ,"post18": {
            "title": "[On-premise] init connection with ssh",
            "content": ". 모니터 없이 진행 가능합니다 n 하지만 iptime 공유기를 기준으로 설명합니다. SSH를 통한 접속 . . Hardware 설정 . Network--(LAN)--Iptime--(LAN)--Raspberry 위와 같이 Iptime 공유기와 라즈베리파이를 연결합니다. . . DHCP로 할당된 IP 확인 . 모니터 없이 초기 설정을 하기 때문에 iptime 관리자 페이지를 통해서 연결된 라즈베리파이가 어떤 내부아이피를 할당 받았는지 확인하는 과정이 필요합니다. . 설치한 Iptime 공유기에 유/무선으로 데스크톱이나 노트북을 연결한 다음에 192.168.0.1 로 접속하면 관리자 페이지로 들어갈 수 있습니다. . 로그인을 한 후에 관리도구를 클릭합니다. . . 그 다음으로 고급 설정 -&gt; 네트워크 관리 -&gt; 내부 네트워크 설정으로 들어가면 라즈베리파이가 할당된 내부 아이피를 확인 할 수 있습니다. . 저의 경우 여러대의 라즈베리파이가 연결되어 있기에 내부 네트워크도 여러개인 것을 확인 할 수 있습니다. . . 포트포워딩 . 저처럼 여러대의 라즈베리파이를 이용할 경우 외부아이피의 포트 22 하나로 여러대의 라즈베리파이에 ssh를 통해 접속할 수 없습니다. 그래서 포트포워딩을 설정해야합니다. . 고급설정 -&gt; NAT/라우터관리 -&gt; 포트포워드 설정 으로 이동합니다. 저의 경우 위와 같이 포트포워딩이 설정되어 있습니다. . . 새로 포트포워드 규칙을 만들려면 . 새규칙 추가 클릭 | 규칙이름에 원하는대로 규칙이름을 작성 | 라즈베리파이가 할당된 내부 IP 주소를내부 IP주소 칸에 입력하고 | 외부포트 범위를 입력, 단일 포트를 쓸 경우 앞부분만 쓰고 ~ 뒤에 부분은 안써도 됩니다. | 내부포트도 입력합니다. | 적용을 클립합니다. | . 예를 들어 위와 같이 설정 했을 때, 외부 아이피 : 59.23.xxx.xxx 외부 포트 : 20004 으로 접속하게 되면 192.168.0.6이 할당된 라즈베리파이의 22번 포트로 접속이 되게 됩니다. . . 접속 확인 . 윈도우에서 접속확인을 하기 위해 putty라는 프로그램을 이용해서 ssh 접속을 시도해보겠습니다. ubuntu server를 처음 설치하면 유저이름은 ubuntu로 설정되어 있습니다. . . Accept를 클릭합니다. . . ubuntu server 처음 설치시에는 비밀번호도 ubuntu로 설정되어있습니다. 타이핑을 해줍시다. . 타이핑할 때 입력이 안되는거처럼 보여도 입력이 정상적으로 되는 중입니다. 그냥 입력하고 엔터를 누르면 정상적으로 작동합니다. . . 처음 접속시 비밀번호를 바꿔야합니다. 비밀번호를 바꾸면 일단 한번 꺼지는데 다시 접속을해 바꾼 비밀번호를 입력합니다. . . 위와 같이 정상적으로 접속되는 것을 확인 할 수 있습니다. .",
            "url": "https://knu-cd2.github.io/blog/on-premise/2022/05/09/on-premise-ssh.html",
            "relUrl": "/on-premise/2022/05/09/on-premise-ssh.html",
            "date": " • May 9, 2022"
        }
        
    
  
    
        ,"post19": {
            "title": "[On-premise] os install",
            "content": "OS 설치 . . 64GB 이상의 SD카드의 해당 방식으로 진행시 오류가 발생할 수 있습니다. 1. 디스크 포맷 (선택 사항) . 이미지는 예시를 보여주기 위해 128GB SD 카드를 이용하였습니다. . 1. SD Card Formatter . . sdcard.org에서 다운 받을 수 있고, 간편하게 SD 카드를 포맷시킬 수 있는 프로그램입니다. . . sd카드를 컴퓨터에 넣고 동작하면 위와 같이 자동적으로 인식이 됩니다. . . Quick format을 실행하면 파일시스템도 알아서 잘 포맷해 줍니다. . . . 클러스터 사이즈의 경우 운영체제를 설치하면 다시 설정됩니다 2. 윈도우에서 포맷 하는 경우 . . 파일시스템은 FAT32로 해야 됩니다. 그리고 블록사이즈는 OS를 설치하면 자동적으로 512로 변경이되기 때문에 블록 사이즈는 기존 설정대로하면 됩니다. . 저는 지금 예시를 알려주기 위해 128GB SD 카드로 진행했기에 exFAT으로 표시되고 있습니다. . 2. OS 설치 . OS의 경우 ubuntu server 20.04 LTS 를 사용했습니다. ubuntu server의 경우 OS를 설치하면 ssh 파일을 생성하는 등 번거러운 과정 필요 없이 바로 ssh로 접속할 수 있고, 용량도 작기에 Desktop 대신 Server를 이용하였습니다. . . 버전의 경우 22.04 LTS나 향후 더 나올 최신 버전을 사용해도 상관 없을 것 같습니다 . . os를 설치할 땐 etcher를 사용합니다. . . UI가 직관적이기 때문에 별도의 설명이 없어도 충분히 쉽게 사용 가능합니다. . . 설치가 완료되면 자동적으로 디스크가 꺼내집니다. .",
            "url": "https://knu-cd2.github.io/blog/on-premise/2022/05/09/on-premise-os.html",
            "relUrl": "/on-premise/2022/05/09/on-premise-os.html",
            "date": " • May 9, 2022"
        }
        
    
  
    
        ,"post20": {
            "title": "[Logstash] How to use file input plugin to read multiple lines in logstash.",
            "content": "로그스태시 file input 플러그인 사용시 한 줄만 읽어지는 문제 . 문제 상황 . 다음과 같이 log 파일을 임시로 생성하고, 이것을 logstash의 file input plugin을 이용하여 읽고 stdout으로 출력하려고 시도하였다. . filter-example.log . [2020-01-02 14:17] [ID1] 192.10.2.6 9500 [INFO] - connected. [2020/01/02 14:19:25] [ID2] 218.25.32.70 1070 [warn] - busy server. . 하지만 파일의 첫번째 line만 출력되고, 두번째 line은 출력되지 않는 문제가 발생하였다. . 원인 . 로그스태시의 File input plugin은 기본적으로 파일을 처음 읽으면 sincedb라는 파일에 읽고 있는 위치를 기록한다. 따라서 로그스태시를 재시작하면 sinedb를 참조하여 파일의 tail, 즉 끝부터 읽는다. 실제 서비스를 운영할 때는 새로 들어오는 데이터에 대해서만 처리해주면 되지만, 테스트할 때는 재시작할 때 파일의 첫 위치부터 읽기를 원한다. . 해결 방법 . mode(읽기모드)를 read 로 설정한다. 그러나 이것만 설정 시 파일이 한번 읽히면 삭제되는 문제가 발생한다. | file_completed_action을 log로 설정한다. 파일을 읽고 나서 삭제하지 않고 기록하자. | file_completed_log_path를 지정한다. 해당 파일을 읽었다고 기록하는 로그를 작성해야한다. 공식 문서에 따르면, 이 파일이 매우 커질 수 있으므로 관리를 주의해야 한다고 한다. | logstash-test.conf . input { file { path =&gt; &quot;/Users/squareyun/Documents/utility/logstash-8.1.1/config/filter-example.log&quot; start_position =&gt; &quot;beginning&quot; mode =&gt; &quot;read&quot; file_completed_action =&gt; &quot;log&quot; file_completed_log_path =&gt; &quot;/Users/squareyun/Documents/utility/logstash-8.1.1/config/test.log&quot; sincedb_path =&gt; &quot;/dev/null&quot; } } output { stdout { } } . Reference . https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html#plugins-inputs-file-mode | .",
            "url": "https://knu-cd2.github.io/blog/logstash/2022/05/06/logstash-file-input-plugin-just-one-line.html",
            "relUrl": "/logstash/2022/05/06/logstash-file-input-plugin-just-one-line.html",
            "date": " • May 6, 2022"
        }
        
    
  
    
        ,"post21": {
            "title": "[On-premise] hardware setting",
            "content": "온프레미스 환경에 사용된 장비 및 부품 . 1. 라즈베리파이 4B 8GB . . 2. 라즈베리파이 4B 4GB . . 3. 디스크 - 32GB MLC . . 4. 공유기 - iptime A3004T . . 5. 스위칭 허브 - iptime H6008 . . 그 외 부품들 . - cat6 30cm 랜선 - 5V 3A 충전기 - 아크릴 케이스 홀더 박스 - 5V 0.2A 냉각팬 .",
            "url": "https://knu-cd2.github.io/blog/on-premise/2022/05/05/on-premise-hardware.html",
            "relUrl": "/on-premise/2022/05/05/on-premise-hardware.html",
            "date": " • May 5, 2022"
        }
        
    
  
    
        ,"post22": {
            "title": "[Elasticsearch] How to deploy a multi-node elasticsearch cluster",
            "content": "엘라스틱서치 다중노드 클러스터 환경 구축 . 1. 인증서 생성 . 클러스터에 포함된 노드들은 서로 transport module을 이용하여 통신을 한다. 통신을 할 때 보안을 위해 TLS를 사용하는데 이를 위해 인증서를 생성하자. . . 이 프로젝트에서는 서로 다른 2개의 서버에서 각각 노드 하나씩 생성하여 클러스터를 구성할 것이다. 첫번째 서버에서 인증서를 생성하고 이 인증서를 각 서버에 복사하는 과정을 진행할 것이다. 작동중인 elasticsearch는 모두 종료하고 진행한다. . CA를 생성한다. filename은 default인 elastic-stack-ca.p12로 진행한다. . ./bin/elasticsearch-certutil ca . 이 CA를 이용해 certificate and private key를 생성한다. filename은 default인 elastic-certificates.p12로 하고, 비밀번호는 기억해둔다. . ./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 . 생성된 elastic-certificates.p12를 config 폴더 안에 certs 폴더를 생성하고 거기에 복사한다. 그리고, 이 파일을 각 서버에 전송하여야 한다. (서버에도 certs 폴더를 생성해야함) linux의 scp 명령어를 이용해 파일을 전송하자. . scp -P {포트번호} /home/{저장 경로}/elasticsearch-8.1.0/config/certs/elastic-certificates.p12 {호스트 이름}@{공개 서버 주소}:/home/c2-elastic/elastic/elasticsearch-8.1.0/config/certs/ . 2. elasticsearch.yml 파일 설정 . 다음과 같이 elasticsearch.yml 파일을 각 서버마다 작성한다. 주석처리 되어있는 것을 해제하여 사용하여도 좋고, 첫 줄에 추가적으로 작성하여도 된다. 노드 이름은 각 서버마다 다르게 지정하여야 한다. . cluster.name: csp-cluster # 동일하기 node.name: c1-elastic # 서버마다 다르게 network.host: [&quot;_local_&quot;, &quot;_site_&quot;] http.port: 9200 # 클러스터에 포함된 노드의 서버 주소. 주의: public IP가 아닌 private IP를 작성한다. # hostname -I 명령어로 private IP 확인 가능함 discovery.seed_hosts: [&quot;192.168.0.6&quot;, &quot;192.168.0.14&quot;] cluster.initial_master_nodes: [&quot;c1-elastic&quot;, &quot;c2-elastic&quot;] # 클러스터에 포함된 노드의 이름 xpack.security.enabled: true xpack.security.enrollment.enabled: true xpack.security.transport.ssl: enabled: true verification_mode: certificate client_authentication: required keystore.path: certs/elastic-certificates.p12 truststore.path: certs/elastic-certificates.p12 transport.host: [_local_, _site_] # 이것은 첫번째 서버에서만 작성하면 됨 . 3. keystore에 비밀번호 저장 . 다음 명령어로 Elasticsearch keystore에 비밀번호를 저장한다. 각 서버마다 실행한다. . ./bin/elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password ./bin/elasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password . 4. HTTP 인증서 생성 . 첫번째 서버에서 다음 명령어로 Elasticsearch HTTP certificate를 생성한다. . ./bin/elasticsearch-certutil http . Generate a CSR? N | Use an existing CA? y | CA Path: /home/c2-elastic/elastic/elasticsearch-8.1.0/elastic-stack-ca.p12 | For how long should your certificate be valid?: 5y | Generate a certificate per node? n | Enter all the hostnames that you need: ubuntu (hostname 명령어로 확인 가능) | Enter all IP addresses that you need: 192.168.0.6 192.168.0.14 (private IP 작성) | Do you wish to change any of these options? n | 생성된 elasticsearch-ssl-http.zip 파일을 압축해제 하면 elasticsearch 폴더와 kibana 폴더가 생성된다. elasticsearch 폴더 내의 http.p12 파일은 config/certs 폴더에 이동하고, 이 파일을 각 서버에 전송한다. (scp 명령어 활용) kibana 폴더 내의 elasticsearch-ca.pem 파일은 키바나 폴더의 config/certs 폴더에 이동한다. . elasticsearch.yml 파일에 다음을 추가한다. . xpack.security.http.ssl: enabled: true keystore.path: certs/http.p12 . 4. keystore에 비밀번호 저장 . 다음 명령어로 Elasticsearch keystore에 비밀번호를 저장한다. 각 서버마다 실행한다. . ./bin/elasticsearch-keystore add xpack.security.http.ssl.keystore.secure_password . 5. kibana.yml 파일 설정 . 키바나를 실행시킬 서버에서 다음과 같이 yml 파일을 설정한다. . server.host: 0.0.0.0 server.publicBaseUrl: &quot;http://192.168.0.6:5601&quot; server.name: &quot;csp-kibana&quot; elasticsearch.hosts: [&quot;https://192.168.0.6:9200&quot;, &quot;https://192.168.0.14:9200&quot;] elasticsearch.ssl.certificateAuthorities: [&quot;/home/c1-elastic/elastic/kibana-8.1.0/config/certs/elasticsearch-ca.pem&quot;] elasticsearch.serviceAccountToken: # 초기 셋팅시 자동으로 생성된 서비스 토큰값 작성 . Reference . https://www.elastic.co/guide/en/elasticsearch/reference/8.1/security-basic-setup.html#encrypt-internode-communication | https://www.elastic.co/guide/en/elasticsearch/reference/8.1/security-basic-setup-https.html#encrypt-kibana-http | https://www.youtube.com/watch?v=id8L4fiCnQE&amp;t=939s | .",
            "url": "https://knu-cd2.github.io/blog/elasticsearch/2022/04/30/deploy-multinode-elasticsearch-cluster.html",
            "relUrl": "/elasticsearch/2022/04/30/deploy-multinode-elasticsearch-cluster.html",
            "date": " • Apr 30, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Us",
          "content": "Kyungpook National University (KNU) . 종합설계프로젝트2 with CSP MOBILE LAB . 이 블로그는 Elasticstack의 오픈소스 생태계에 기여하기 위해 만들어졌습니다. . [Member] . 조동현 @JoDongHyuen | 윤우혁 @squareyun | 이준배 @junnbae | 신현석 @quf265 | .",
          "url": "https://knu-cd2.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  
  

  

  
  

  
  

}