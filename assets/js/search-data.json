{
  
    
        "post0": {
            "title": "SSH connect with vscode",
            "content": "서론 . 원격 서버에 접속하여 사용할 때 파일 시스템을 한눈에 보고 싶을 때나, vim 명령어가 익숙하지 않아 불편할 때가 있습니다. . 그럴 때 vscode의 원격 접속 확장 프로그램을 사용하면 편리하게 서버에 접속할 수 있습니다. . 확장 프로그램 설치 . . vscode가 설치되어 있지 않다면 공식 사이트에서 다운로드하세요. vscode를 실행시키고, 좌측 메뉴바에서 마켓플레이스에 들어가 SSH를 검색합니다. . . 위 사진에 해당하는 확장 프로그램을 설치해주세요. . 원격 접속 세팅 . 설치 후 vscode 화면의 좌측 하단의 &gt; &lt; 버튼을 클릭하세요. . . . Connect to Host… &gt; Configure SSH Hosts… &gt; {save points} 순으로 선택하여 config 파일을 생성하고 작성합니다. . Host test_server HostName xxx.xxx.xxx.xxx User test_user Port xxxx . Host는 서버 정보 이름을 무엇으로 정할지 나타내는 것이고, HostName, User, Port는 접속할 원격 서버 정보를 작성합니다. . 작성을 완료 하셨으면 다시 버튼을 클릭하여 아까 저장해둔 정보로 접속을 해봅시다. . . 서버의 비밀번호를 작성하면 접속에 성공합니다 ! . 비밀번호 작성하는 것이 귀찮아졌다면, 원격 접속 자동 로그인 게시글을 참고해주세요. .",
            "url": "https://knu-cd2.github.io/blog/ssh/2022/05/16/vscode-ssh.html",
            "relUrl": "/ssh/2022/05/16/vscode-ssh.html",
            "date": " • May 16, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "SSH connect auto login with vscode",
            "content": "서론 . vscode를 이용하여 원격 접속할 때 비밀번호를 매번 입력하는 과정이 귀찮습니다. . 꼭 vscode를 이용할 때 뿐만 아니라 shell에서 접속할 때도 마찬가지입니다. . 원격 접속을 할 때 비밀번호를 입력하지 않고 자동으로 인증되도록 설정하는 방법을 알아보겠습니다. . SSH key 생성하기 . SSH key는 공개 키 (Public Key)와 비공개 키 (Private Key)로 이루어져 있습니다. . 비공개 키 id_rsa는 로컬 컴퓨터에 존재해야하며, 공개 키 id_rsa.pub는 원격 서버에 존재해야합니다. . 비공개 키는 외부에 절대로 노출되어서는 안됩니다. . SSH key를 생성하고 공개 키를 원격 서버에 저장하는 과정을 알아보겠습니다. . SSH key 생성 . . windows는 git bash를 이용하여 진행하면 동일하게 진행할 수 있습니다. 우선 SSH key가 이미 존재하는지 확인해봅시다. . cat ~/.ssh/id_rsa.pub . ssh-rsa로 시작하는 문자열이 출력된다면 다음 단계로 진행하세요. . 없다면 다음을 명령어로 키를 생성합니다. . ssh-keygen -t rsa . 생성할 때 모두 default로 설정하여도 좋습니다. 따로 입력하지 않고 Enter를 3번 눌러 진행하세요. . 원격 서버에 저장 . ssh-key가 생성되었다면 출력해보세요. . cat ~/.ssh/id_rsa.pub . ssh-rsa로 시작하는 문자열을 복사하여 원격 서버의 ~/.ssh/authorized_keys에 등록하도록 하겠습니다. . vi ~/.ssh/authorized_keys . 여기에 아까 복사한 ssh-rsa 문자열을 붙여넣고 저장합니다. . vscode config 파일 수정 . 이제, vscode에서 이 키를 가지고 인증하도록 세팅해주기만 하면 됩니다. . 다음과 같이 접속 config 파일을 수정하세요. . Host test_server HostName xxx.xxx.xxx.xxx User test_user Port xxxx IdentityFile ~/.ssh/id_rsa . Done! . 이제 비밀번호 없이 원격 접속이 가능합니다. .",
            "url": "https://knu-cd2.github.io/blog/ssh/2022/05/16/vscode-ssh-without-password.html",
            "relUrl": "/ssh/2022/05/16/vscode-ssh-without-password.html",
            "date": " • May 16, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Using curl with ElasticSearch",
            "content": "ElasticSearch에서 curl 사용하기 . Elasticsearch는 REST API를 사용하기 때문에 curl을 이용해서 간편하게 데이터를 조회하고, 추가하거나 삭제할 수 있습니다. 간단한 사용 예시를 보여드리겠습니다. . 1. curl 에러 . curl localhost:9200 . 이 커맨드를 실행하면 클러스터의 상태 정보를 알 수 있습니다. 먼저 이 커맨드를 콘솔에 입력해보겠습니다. . . Elasticsearch가 실행 중이지 않으면 Connection refuesed 에러가 발생하므로 Elasticsearch를 꼭 가동해주세요. . 다시 Elasticsearch가 가동 중인 커맨드를 입력하겠습니다. . . 이번에는 Empty reply from server 라며 클러스터의 상태정보를 알려주지 않습니다. . Elasticsearch 버전 7에서는 이러한 커맨드로 확인이 가능했지만, 버전 8이 되면서 보안설정이 생겨 단순한 curl 커맨드로는 Elasticsearch에 접근할 수 없습니다. . 2. ID, Password를 이용한 curl . 이번에는 Elasticsearch의 ID와 Password가 추가된 curl을 입력하겠습니다. . curl -u &quot;elastic:changeme&quot; -k https://localhost:9200 . ID: elastic Password: changeme ID와 Password는 사용 중인 ID와 Password를 입력하셔야 합니다. . . 아까와는 다르게 클러스터의 상태를 조회할 수 있습니다. . 3. http_ca.crt 인증서를 이용한 curl . 인증서와 Elasticsearch의 ID와 Password를 추가해 curl을 이용할 수 있습니다. . curl --cacert /home/c2-kafka/elastic/elasticsearch-8.1.0/config/certs/http_ca.crt -u &quot;elastic:kibana&quot; -X GET https://localhost:9200 . curl 커맨드 중간에 http_ca.crt의 경로를 입력해야 합니다. http_ca.crt의 상대경로가 아닌 절대경로를 입력하시면 됩니다. . . 이 커맨드 또한 아까 전과 같은 클러스터의 상태 정보를 알아낼 수 있습니다. .",
            "url": "https://knu-cd2.github.io/blog/elasticsearch/2022/05/16/about-curl.html",
            "relUrl": "/elasticsearch/2022/05/16/about-curl.html",
            "date": " • May 16, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Reset ElasticSearch Token and Kibana Password",
            "content": "ElasticSearch Toekn, Password 초기화하기 . Elasticsearch 첫 화면에서 토큰 또는 비밀번호를 분실하시는 경우가 있을 수 있습니다. Elasticsearch와 Kibana를 삭제 후 재설치 하시면 토큰과 비밀번호를 재발급 받으실 수 있습니다. . 하지만 이러한 방법은 너무 번거롭기에, 삭제하지 않고 토큰과 비밀번호를 재발급 받을 수 있는 방법을 알려드리겠습니다. . 1. ElasticSearch 토큰 초기화하기 . 먼저 Elasticsearch를 실행시켜야 합니다. 그리고 Elasticsearch 폴더의 bin 폴더로 가서 . ./elasticsearch-create-enrollment-token -s kibana . 위의 커맨드를 실행시키면 됩니다. . . 그러면 사진과 같이 토큰이 초기화됩니다. . 이 토큰을 Kibana 초기 접속화면에 입력하시면 키바나 사용이 가능합니다. . 2. Kibana 비밀번호 초기화하기 . Kibana의 비밀번호를 분실하실 때도 Elasticsearch를 실행시키고, Elasticserach 폴더의 bin 폴더로 가서 . /elasticsearch-reset-password -u elastic . 위의 커맨드를 실행시키면 . . 사진과 같이 터미널에 비밀번호를 출력할 것인지 묻습니다. 그냥 y를 입력하면 . . 터미널에 비밀번호가 나타납니다. 이 비밀번호를 Kibana에 입력합니다.(초기 Username: elastic) . . Kibana 로그인이 완료되었습니다. . 비밀번호를 변경하고 싶으시면 우측상단에 프로필 창을 클릭합니다. . 사진과 같이 Kibana의 비밀번호를 원하는 비밀번호로 수정하실 수 있습니다! . 3. Elasticsearch를 실행시키지 않았을 때 . Elasticsearch를 실행시키지 않고 커맨드를 날리면 ERROR: Failed to determine the health of the cluster. 라는 에러가 발생합니다. . 그러므로 꼭 Elasticsearch를 실행시키고 커맨드를 날려주셔야 합니다. .",
            "url": "https://knu-cd2.github.io/blog/elasticsearch/kibana/2022/05/15/token-password.html",
            "relUrl": "/elasticsearch/kibana/2022/05/15/token-password.html",
            "date": " • May 15, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Kafka download and setting",
            "content": "카프카 다운로드 및 설정 . 서버에 카프카 다운로드 후 로컬과 통신을 설정하는 과정입니다. . . 카프카 다운로드 . https://kafka.apache.org/downloads 위 사이트로 가서 카프카 다운로드 링크를 복사하도록 하겠습니다. . . . wget https://dlcdn.apache.org/kafka/3.1.0/kafka_2.13-3.1.0.tgz . 앞에 숫자는 Scalar 버전이고, 뒤에 숫자는 카프카 버전입니다. 저는 Scalar는 2.13버전, 카프카는 3.1.0 버전으로 진행하겠습니다. . . . tar -xzvf kafka_2.13-3.1.0.tgz . tar 명령어를 통해 압축을 풀어줍니다. . . . 자바 설치 . 카프카를 구동하기 위해서는 자바가 필요합니다. 자바도 설치해보도록 하겠습니다. . . sudo apt install openjdk-8-jdk-headless . 저의 경우 자바 8 버전을 설치하였습니다. . . 설치가 완료되었고 테스트 할겸 java와 javac의 버전도 출력해보았습니다. . . . 카프카 사용 메모리 설정 . 이 부분은 무료 클라우드 인스턴스를 사용하거나 온프래미스 구축시 장비의 메모리가 부족하신 분들만 진행하시면 됩니다. . vi ~/.bashrc 명령어를 사용해 배쉬쉘에 들어간 다음에 . | export KAFKA_HEAP_OPTS=&quot;-Xmx400m -Xms400m&quot; 를 입력후 저장해줍니다. . | source ./bashrc를 해준다음 echo $KAFKA_HEAP_OPTS를 입력해 환경변수가 잘 지정되었는지 확인 해줍니다. . | 저 같은 경우 메모리 8G 라즈베리파이를 이용했기에 이 과정은 넘어갔습니다. . . . server.properties 설정 . 카프카를 로컬에서 통신하기 위해 server.properties를 설정해보겠습니다. . . cd kafka_2.13-3.1.0 vim config/server.properties . . 그 다음 advertised.listeners를 찾아서 주석을 풀어주고 설정을 합니다. . 저 같은 경우 여러대의 라즈베리파이가 외부아이피 하나에 연결되어 있기에 기존의 9092포트가 아닌 30014로 설정하였습니다. 아이피 부분은 클라우드의 인스턴스나 본인이 구축한 온프레미스 환경의 외부아이피를 입력하시면 됩니다. . . 그 후 포트포워딩도 진행하였습니다. 로컬과 통신을 위해 새로 추가한 규칙은 순위 16의 규칙입니다. . . 추가적으로 카프카를 구동하기전에 server.properties 에서 log.dirs에 설정된 값에 해당하는 디렉토리가 없다면 생성해주도록 합니다. . . . 카프카 실행 . 카프카를 실행하기 위해서는 주키퍼를 실행한 다음 카프카를 실행하여야 합니다. 주키퍼의 경우 다운받은 카프카에 함께 포함되어 있습니다. . 우선 주키퍼를 실행해보도록 하겠습니다. . bin/zookeeper-server-start.sh -daemon config/zookeeper.properties . 그 다음으로 카프카를 실행해보도록 하겠습니다. . bin/kafka-server-start.sh -daemon config/server.properties . -daemon 옵션은 백그라운드로 동작하도록 해주는 옵션입니다. . 실행을 한 후에 jps를 커맨드라인에 입력하면 위와 같이 QuorumPeerMain(주키퍼) 와 Kafka가 동작 중인 것을 확인 할 수 있습니다. . . . 로컬과 카프카 통신 확인 . 저의 로컬 환경은 Window10 에서 WSL을 활용하였습니다. . WSL에서도 서버에 설치한 카프카와 자바의 버전과 동일하게 카프카와 자바를 설치해줍니다. 위에서 설치시 활용한 커맨드를 그대로 입력하면 됩니다 . . 그 후 정상적으로 통신이 가능한지 테스트를 진행합니다. . bin/kafka-broker-api-versions.sh --bootstrap-server 59.23.xxx.xxx:30014 . 통신이 정상적으로 잘 되는 것을 확인 할 수 있습니다. . . .",
            "url": "https://knu-cd2.github.io/blog/kafka/2022/05/15/kafka-download.html",
            "relUrl": "/kafka/2022/05/15/kafka-download.html",
            "date": " • May 15, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "PKIX path building failed error",
            "content": "문제 상황 . Logstash와 Elasticsearch를 연동하는 과정에서 다음과 같은 에러가 발생하였습니다. . . PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target . 이는 Elasticstack 8.0 버전부터 default로 보안 설정이 적용되어 생기는 문제로 보안 관련 처리를 해주어야 제대로 동작합니다. . 해결 방법 . 두 가지 방법이 있습니다. . SSL 자격 확인을 하지 않도록 설정하는 방법 | SSL 자격 인증서를 등록하는 방법 | 1번 방법에 대한 해결법은 이 게시글을 참고해주세요. . 2번 방법에 대한 해결법을 설명해드리겠습니다. . Elasticsearch 인증서 생성 . 다음 명령어를 입력하여 .cer 인증서를 생성해줍니다. . echo -n | openssl s_client -connect localhost:9200 | sed -ne &#39;/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p&#39; &gt; ./ca_logstash.cer . 생성된 파일을 ${LS_HOME}/config/certs폴더로 이동시킵니다. . conf 파일 수정 . config 파일을 다음과 같이 cacert과 ssl을 추가하여 변경합니다. . ... output { elasticsearch { index =&gt; &quot;output&quot; hosts =&gt; [&quot;https://192.168.0.6:9200&quot;, &quot;https://192.168.0.14:9200&quot;, &quot;https://192.168.0.15:9200&quot;] user =&gt; &quot;elastic&quot; password =&gt; &quot;yourpassword&quot; ssl =&gt; true cacert =&gt; &quot;/home/c1-elastic/elastic/logstash-8.1.0/config/certs/ca_logstash.cer&quot; } stdout {} } . . Elasticsearch가 다중 노드로 구성되어 있다면 hosts에 해당 노드를 모두 추가하여야 합니다. 수정 후 다시 실행하여 봅시다. . ./bin/logstash -f config/test.conf . . 사진과 같이 정상적으로 실행되었음을 확인할 수 있습니다. .",
            "url": "https://knu-cd2.github.io/blog/logstash/2022/05/14/pkix-path-building-failed.html",
            "relUrl": "/logstash/2022/05/14/pkix-path-building-failed.html",
            "date": " • May 14, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "How to connect Logstash with Elasticsearch",
            "content": "Logstash에서 Elasticsearch로 데이터 저장하는 방법 . 데이터 파이프라인을 구축하기 위해 Logstash에서 가공한 데이터를 Elasticsearch로 전송하여 데이터를 저장하고자 합니다. . 우선, Elasticsearch은 실행되어 있는 상태이여야 합니다. 다른 게시글을 참고하여 실행합니다. . 다음으로 config 파일 test.conf을 작성합니다. 이번 예제에서는 Elasticsearch에서 발생하는 로그를 받아와 이것을 Elasticsearch로 전송하여 인덱스 output을 생성하여 저장하고, 눈으로 확인하기 위해 표준 출력으로도 받아보겠습니다. . input { file { path =&gt; &quot;/home/c1-elastic/elastic/elasticsearch-8.1.0/logs/gc.log&quot; start_position =&gt; &quot;beginning&quot; sincedb_path =&gt; &quot;/dev/null&quot; } } output { elasticsearch { index =&gt; &quot;output&quot; hosts =&gt; [&quot;https://127.0.0.1:9200&quot;] user =&gt; &quot;elastic&quot; password =&gt; &quot;yourpassword&quot; } stdout {} } . 작성한 config 파일을 이용하여 로그스태시를 실행하여 봅시다. . ./bin/logstash -f config/test.conf . 에러 발생 . . 실행시 다음과 같은 에러가 발생합니다. . PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target . 이는 Elasticstack 8.0 버전부터 default로 보안 설정이 적용되어 생기는 문제로 보안 관련 처리를 해주어야 제대로 동작합니다. . certification 에러 해결 . 에러 해결 방법에는 두 가지 방법이 있습니다. . SSL 자격 확인을 하지 않도록 설정하는 방법 | SSL 자격 인증서를 등록하는 방법 | 여기서는 우선 1번을 이용한 해결 방법을 소개하도록 하겠습니다. . 2번 방법에 대한 해결법은 다음 게시물을 참고해주세요. . conf 파일 변경 . elasticsearch 플로그인에 다음 두 옵션 ssl_certificate_verification과 ssl을 추가합니다. . ... output { elasticsearch { index =&gt; &quot;output&quot; hosts =&gt; [&quot;https://127.0.0.1:9200&quot;] user =&gt; &quot;elastic&quot; password =&gt; &quot;yourpassword&quot; ssl_certificate_verification = false ssl = true } stdout {} } . 수정 후 다시 실행하여 봅시다. . ./bin/logstash -f config/test.conf . . 정상적으로 실행되었습니다! output에서 표준 출력으로 잘 출력되었음을 확인할 수 있습니다. . Elasticsearch에서 확인 . 실제 elasticsearch에도 인덱스가 만들어졌는지 확인해봅시다. . 다음과 같이 명령어 curl를 날려보세요. . curl -u &quot;elastic:yourpassword&quot; -k https://localhost:9200/output?pretty . . 사진과 같이 정상적으로 인덱스로 저장되었음을 확인할 수 있습니다. .",
            "url": "https://knu-cd2.github.io/blog/logstash/2022/05/14/logstash-to-elasticsearch.html",
            "relUrl": "/logstash/2022/05/14/logstash-to-elasticsearch.html",
            "date": " • May 14, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "How to handle vm.max_map_count [65530] error in elasticsearch",
            "content": "문제 상황 . 초기 엘라스틱서치 실행 후 다음과 같이 max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 라고 오류가 발생할 때가 있습니다. . . 해결법 . 위와 같이 에러가 발생하였다면 다음과 같이 입력하여 vm.max_map_count를 262144로 변경하면 됩니다. . sudo sysctl -w vm.max_map_count=262144 . 왜 이런 에러가 발생할까? . Elasticsearch는 MMap FS라는 타입의 디렉터리를 사용하여 샤드 인덱스를 저장합니다. | 이 타입은 파일을 메모리에 매핑하여 저장하는데, 매핑되는 파일과 동일한 크기의 가상 메모리 주소 공간이 필요합니다. | 하지만, 운영 체제의 기본 제한이 너무 낮으므로 out of memory를 유발합니다. | 충분한 가상 메모리 주소 공간을 허용하라고 경고하기 때문에 이 에러가 발생한다고 알 수 있습니다. | . Reference . https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html | https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-store.html#file-system | .",
            "url": "https://knu-cd2.github.io/blog/elasticsearch/2022/05/13/vm_max_map_count_error.html",
            "relUrl": "/elasticsearch/2022/05/13/vm_max_map_count_error.html",
            "date": " • May 13, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "Intergrating ElasticSearch & Kibana",
            "content": "ElasticSearch와 Kibana 연동하기(8.1.0) . Elastic Stack이 7버전에서 8버전으로 바뀌면서 많은 부분이 수정되었습니다. Elasticsearch와 Kibana 연동 부분에서도 많은 변화가 있어 기존 버전 7에서의 연동방식와 차이가 있습니다. 이 글에서는 버전 8의 Elasticsearch와 Kibana 연동 방법을 설명해드리겠습니다. . 1. ElasticSearch 실행하기 . 먼저 Elasticsearch를 실행시켜는 법을 알려드리겠습니다. . 설치한 Elasticsearch 폴더 내부에 많은 파일과 폴더가 있는 걸 알 수 있습니다. Elasticsearch를 실행시킬려면 bin에 있는 elasticsearch를 실행시키면 됩니다. . ./bin/elasticsearch . . Elasticsearch를 최초로 실행시키면 이렇게 토큰과 Kibana에 접속할 비밀번호를 보여줍니다. 이를 잘 보관해두셔야 Kibana와 연동이 가능합니다. 이제 Kibana를 실행시켜 Elasticserach와 Kibana를 연동시켜 보겠습니다. . 2. Kibana 외부접속 . 로컬 컴퓨터에서 자신만 Kibana에 접속하시는 분들은 상관 없으시겠지만, Elasticsearch Stack을 사용하면 아마 Kibana에서 외부접속은 필요하실 겁니다. 외부접속을 할려면 kibana폴더 내부에 config 폴더에 kibana.yml 이 있습니다. . vi config/kibana.yml . 커맨드를 입력해서 kibana.yml 파일을 수정하겠습니다. . 초기에는 server.host: “localhost”가 주석처리 되어 있습니다. 주석을 지우고 . server.host: 0.0.0.0 . 으로 수정하시면 외부접속이 가능합니다. . 3. Kibana 실행하기 . 설치한 Kibana 폴더 내부입니다. Kibana도 bin폴더에 있는 kibana를 실행하면 됩니다. Kibana를 실행하기 전 위에서 최초로 구동시킨 Elasticsearch가 실행 중이어야 합니다. . ./bin/kibana . . 그럼 터미널에서 이렇게 코드값을 주고 Kibana가 실행됩니다. . Kibana의 port는 5601로 설정되어 있습니다. localhost:5601 또는 ServerIP:5601 로 접속하면, . 이렇게 Kibana에서 토큰을 입력하라고 합니다. 그러면 아까 Elasticsearch에서 발행된 토큰을 입력해줍니다. . 토큰이 입력되면 kibana는 코드를 입력하라 합니다. . Kibana를 실행시킬 때 코드를 입력해줍니다. . 이렇게 Elasticsearch와 Kibana의 연동이 끝납니다. . 로그인 창이 나오는데요. 초기에는 Username: elastic Password는 Elasticsearch를 최초로 실행시킬 때 나오는 password를 입력해줍니다. . 이제 Kibana에 접속이 완료되었습니다. .",
            "url": "https://knu-cd2.github.io/blog/elasticsearch/kibana/2022/05/11/intergrating-elasticsearch-and-kibana.html",
            "relUrl": "/elasticsearch/kibana/2022/05/11/intergrating-elasticsearch-and-kibana.html",
            "date": " • May 11, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "Download Logtash",
            "content": "리눅스 서버에 Logstash 8.1.0 설치하는 방법 . wget을 통한 Logstash 설치 . wget은 Web Get의 약어로 웹 상의 파일을 다운로드 받을 때 사용하는 리눅스 명령어로 비 상호작용 네트워크 다운로더입니다. . https://www.elastic.co/kr/downloads/past-releases/logstash-8-1-0 . 위 사이트에서 제공하는 파일을 다음과 같이 wget 명령어로 리눅스 서버에 설치합니다. . wget https://artifacts.elastic.co/downloads/logstash/logstash-8.1.0-linux-aarch64.tar.gz . . 이렇게 logstash의 압축파일을 다운로드 받았습니다. 이 파일을 압축 해제하기 위해 다음과 같이 입력합니다. . tar -zxvf logstash-8.1.0-linux-aarch64.tar.gz . . 이렇게 로그스태시 설치는 완료하였습니다. . 다음은 실행을 통해 정상적으로 설치가 완료되었는지 확인을 해 봅시다. . 실행을 통한 설치 확인 . 설치된 폴더로 이동하여 다음과 같이 명령어를 입력해봅시다. . bin/logstash -e &#39;input { stdin { } } output { stdout {} }&#39; . 이것은 input filter를 표준 입력으로, output filter를 표준 출력으로 처리하도록 하는 명령어입니다. 실행 후 Pipelines running 이라는 메세지가 뜨면 아무 문자나 입력해봅시다. . . 다음과 같이 정상적으로 설치가 되었고, 입출력되는 것을 확인하였습니다. .",
            "url": "https://knu-cd2.github.io/blog/logstash/2022/05/11/install-logstash.html",
            "relUrl": "/logstash/2022/05/11/install-logstash.html",
            "date": " • May 11, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "Download ElasticSearch & Kibana",
            "content": "리눅스 서버에 ElasticSearch와 Kibana 설치하기(8.1.0) . 1. ElasticSearch 설치 . https://www.elastic.co/kr/downloads/past-releases/elasticsearch-8-1-0 에 접속하시면 . 위와 같은 화면이 나옵니다. . LINUX X86_64, LINUX AARCH64 둘 중 자신의 리눅스 서버에 맞는 프로그램을 설치해야 합니다. . 설치버튼을 우클릭해서 ‘링크 주소 복사’ 클릭하고 리눅스 터미널에 . wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.1.0-linux-aarch64.tar.gz . 이렇게 입력합니다. . 그러면 사진과 같이 tar.gz파일 설치가 완료됩니다. . . 그러고 이 알집을 풀어주기 위해 . tar -zxvf elasticsearch-8.1.0-linux-aarch64.tar.gz . 커맨드를 입력합니다. . . 그러면 이렇게 elasticsearch-8.1.0 폴더가 생성되면서 ElasticSearch의 설치가 완료됩니다. . 2. Kibana 설치 . Kibana의 설치법은 ElasticSearch와 동일합니다. . https://www.elastic.co/kr/downloads/past-releases/kibana-8-1-0로 접속하시면 . 여기서도 우클릭으로 링크 주소 복사 후 리눅스 터미널에 아래 커맨드를 입력시킵니다. . wget wget https://artifacts.elastic.co/downloads/kibana/kibana-8.1.0-linux--aarch64.tar.gz . 이렇게 tar.gz 파일 설치가 완료됩니다. . 이 파일도 . tar -zxvf kibana-8.1.0-linux-aarch64.tar.gz . 커맨드를 입력해 압축을 해제합니다. . 이렇게 ElasticSearch와 Kibana의 설치가 끝났습니다. . 연동하는 방법은 다음 게시글에서 알아보도록 하겠습니다. .",
            "url": "https://knu-cd2.github.io/blog/elasticsearch/kibana/2022/05/11/install-elasticsearch-kibana.html",
            "relUrl": "/elasticsearch/kibana/2022/05/11/install-elasticsearch-kibana.html",
            "date": " • May 11, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "On-premise username change",
            "content": "유저 이름 바꾸기 . 서버 초기에 설치하면 유저이름이 ubuntu로 되어있습니다. 하지만 여러개의 클러스터를 운용할 때, 모든 클러스터 유저가 ubuntu로 되어 있으면 헷갈리기에 변경을 하도록 하겠습니다. . ubuntu 유저명을 바꾸는 대신 새로 유저를 생성하는 방법을 써도 됩니다. . . . . root로 ssh 접속하기 . 일반 유저로 접속 후 sudo passwd root를 입력한 후 본인이 설정하고자 하는 비밀번호를 입력합니다. 해당 커맨드는 os 처음 설치시, root 비밀번호를 설정하는 커맨드입니다. . . sudo vim /etc/ssh/sshd_config 를 입력합니다. root를 통한 ssh 접속은 기본적으로 거부되기 때문에 해당 파일의 설정을 변경해주어야 합니다. . . PermitRootLogin 속성을 찾아서 주석을 풀고 prohibit-password는 지우고 yes로 바꿔줍니다. vim을 사용하실 경우 : PermitRootLogin 을 입력하면 쉽게 찾으실 수 있습니다. . . 변경 사항을 반영하기 위해 systemctl restart sshd를 입력합니다. . . 해당 과정을 거치면 ssh를 root 계정을 통해서 접속이 가능해지게 됩니다. . . . . 사용자 이름 바꾸기 . usermod -l newname oldname 을 입력합니다 소문자 L입니다. 저의 경우 ubuntu를 simul로 바꾸어 보겠습니다. . . usermod -m -d /home/newname newname을 입력합니다. 둘 다 newname으로 적은건 오타가 아닙니다! . . 위 커맨드 입력을 실수하면 홈디렉토리가 사라질 수 있습니다. 대처법은 따로 포스팅하였습니다. . 추가적으로 초기에 그룹 이름도 ubuntu로 되어 있는데, 그룹 이름도 바꾸고 싶은 경우 groupmod -m newname oldname 커맨드를 입력해주시면 됩니다. 저 같은 경우 이 부분은 생략하였습니다. . . . . 바뀐 사용자로 로그인 . 바뀐 사용자로 로그인 한 다음에는 이제 다시 루트 로그인을 막아야합니다. . . sudo vim /etc/ssh/sshd_config 를 입력합니다. 그 다음 PermitRootLogin 부분 주석 처리를 합니다. . . systemlctl restart sshd를 하면 정상적으로 root 로그인은 막히게 됩니다. .",
            "url": "https://knu-cd2.github.io/blog/on-premise/2022/05/10/on-premise-change-username.html",
            "relUrl": "/on-premise/2022/05/10/on-premise-change-username.html",
            "date": " • May 10, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "On-premise init connection with ssh",
            "content": ". 모니터 없이 진행 가능합니다 n 하지만 iptime 공유기를 기준으로 설명합니다. SSH를 통한 접속 . . Hardware 설정 . Network--(LAN)--Iptime--(LAN)--Raspberry 위와 같이 Iptime 공유기와 라즈베리파이를 연결합니다. . . DHCP로 할당된 IP 확인 . 모니터 없이 초기 설정을 하기 때문에 iptime 관리자 페이지를 통해서 연결된 라즈베리파이가 어떤 내부아이피를 할당 받았는지 확인하는 과정이 필요합니다. . 설치한 Iptime 공유기에 유/무선으로 데스크톱이나 노트북을 연결한 다음에 192.168.0.1 로 접속하면 관리자 페이지로 들어갈 수 있습니다. . 로그인을 한 후에 관리도구를 클릭합니다. . . 그 다음으로 고급 설정 -&gt; 네트워크 관리 -&gt; 내부 네트워크 설정으로 들어가면 라즈베리파이가 할당된 내부 아이피를 확인 할 수 있습니다. . 저의 경우 여러대의 라즈베리파이가 연결되어 있기에 내부 네트워크도 여러개인 것을 확인 할 수 있습니다. . . 포트포워딩 . 저처럼 여러대의 라즈베리파이를 이용할 경우 외부아이피의 포트 22 하나로 여러대의 라즈베리파이에 ssh를 통해 접속할 수 없습니다. 그래서 포트포워딩을 설정해야합니다. . 고급설정 -&gt; NAT/라우터관리 -&gt; 포트포워드 설정 으로 이동합니다. 저의 경우 위와 같이 포트포워딩이 설정되어 있습니다. . . 새로 포트포워드 규칙을 만들려면 . 새규칙 추가 클릭 | 규칙이름에 원하는대로 규칙이름을 작성 | 라즈베리파이가 할당된 내부 IP 주소를내부 IP주소 칸에 입력하고 | 외부포트 범위를 입력, 단일 포트를 쓸 경우 앞부분만 쓰고 ~ 뒤에 부분은 안써도 됩니다. | 내부포트도 입력합니다. | 적용을 클립합니다. | . 예를 들어 위와 같이 설정 했을 때, 외부 아이피 : 59.23.xxx.xxx 외부 포트 : 20004 으로 접속하게 되면 192.168.0.6이 할당된 라즈베리파이의 22번 포트로 접속이 되게 됩니다. . . 접속 확인 . 윈도우에서 접속확인을 하기 위해 putty라는 프로그램을 이용해서 ssh 접속을 시도해보겠습니다. ubuntu server를 처음 설치하면 유저이름은 ubuntu로 설정되어 있습니다. . . Accept를 클릭합니다. . . ubuntu server 처음 설치시에는 비밀번호도 ubuntu로 설정되어있습니다. 타이핑을 해줍시다. . 타이핑할 때 입력이 안되는거처럼 보여도 입력이 정상적으로 되는 중입니다. 그냥 입력하고 엔터를 누르면 정상적으로 작동합니다. . . 처음 접속시 비밀번호를 바꿔야합니다. 비밀번호를 바꾸면 일단 한번 꺼지는데 다시 접속을해 바꾼 비밀번호를 입력합니다. . . 위와 같이 정상적으로 접속되는 것을 확인 할 수 있습니다. .",
            "url": "https://knu-cd2.github.io/blog/on-premise/2022/05/09/on-premise-ssh.html",
            "relUrl": "/on-premise/2022/05/09/on-premise-ssh.html",
            "date": " • May 9, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "On-premise os install",
            "content": "OS 설치 . . 64GB 이상의 SD카드의 해당 방식으로 진행시 오류가 발생할 수 있습니다. 1. 디스크 포맷 (선택 사항) . 이미지는 예시를 보여주기 위해 128GB SD 카드를 이용하였습니다. . 1. SD Card Formatter . . sdcard.org에서 다운 받을 수 있고, 간편하게 SD 카드를 포맷시킬 수 있는 프로그램입니다. . . sd카드를 컴퓨터에 넣고 동작하면 위와 같이 자동적으로 인식이 됩니다. . . Quick format을 실행하면 파일시스템도 알아서 잘 포맷해 줍니다. . . . 클러스터 사이즈의 경우 운영체제를 설치하면 다시 설정됩니다 2. 윈도우에서 포맷 하는 경우 . . 파일시스템은 FAT32로 해야 됩니다. 그리고 블록사이즈는 OS를 설치하면 자동적으로 512로 변경이되기 때문에 블록 사이즈는 기존 설정대로하면 됩니다. . 저는 지금 예시를 알려주기 위해 128GB SD 카드로 진행했기에 exFAT으로 표시되고 있습니다. . 2. OS 설치 . OS의 경우 ubuntu server 20.04 LTS 를 사용했습니다. ubuntu server의 경우 OS를 설치하면 ssh 파일을 생성하는 등 번거러운 과정 필요 없이 바로 ssh로 접속할 수 있고, 용량도 작기에 Desktop 대신 Server를 이용하였습니다. . . 버전의 경우 22.04 LTS나 향후 더 나올 최신 버전을 사용해도 상관 없을 것 같습니다 . . os를 설치할 땐 etcher를 사용합니다. . . UI가 직관적이기 때문에 별도의 설명이 없어도 충분히 쉽게 사용 가능합니다. . . 설치가 완료되면 자동적으로 디스크가 꺼내집니다. .",
            "url": "https://knu-cd2.github.io/blog/on-premise/2022/05/09/on-premise-os.html",
            "relUrl": "/on-premise/2022/05/09/on-premise-os.html",
            "date": " • May 9, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "How to use file input plugin to read multiple lines in logstash.",
            "content": "로그스태시 file input 플러그인 사용시 한 줄만 읽어지는 문제 . 문제 상황 . 다음과 같이 log 파일을 임시로 생성하고, 이것을 logstash의 file input plugin을 이용하여 읽고 stdout으로 출력하려고 시도하였다. . filter-example.log . [2020-01-02 14:17] [ID1] 192.10.2.6 9500 [INFO] - connected. [2020/01/02 14:19:25] [ID2] 218.25.32.70 1070 [warn] - busy server. . 하지만 파일의 첫번째 line만 출력되고, 두번째 line은 출력되지 않는 문제가 발생하였다. . 원인 . 로그스태시의 File input plugin은 기본적으로 파일을 처음 읽으면 sincedb라는 파일에 읽고 있는 위치를 기록한다. 따라서 로그스태시를 재시작하면 sinedb를 참조하여 파일의 tail, 즉 끝부터 읽는다. 실제 서비스를 운영할 때는 새로 들어오는 데이터에 대해서만 처리해주면 되지만, 테스트할 때는 재시작할 때 파일의 첫 위치부터 읽기를 원한다. . 해결 방법 . mode(읽기모드)를 read 로 설정한다. 그러나 이것만 설정 시 파일이 한번 읽히면 삭제되는 문제가 발생한다. | file_completed_action을 log로 설정한다. 파일을 읽고 나서 삭제하지 않고 기록하자. | file_completed_log_path를 지정한다. 해당 파일을 읽었다고 기록하는 로그를 작성해야한다. 공식 문서에 따르면, 이 파일이 매우 커질 수 있으므로 관리를 주의해야 한다고 한다. | logstash-test.conf . input { file { path =&gt; &quot;/Users/squareyun/Documents/utility/logstash-8.1.1/config/filter-example.log&quot; start_position =&gt; &quot;beginning&quot; mode =&gt; &quot;read&quot; file_completed_action =&gt; &quot;log&quot; file_completed_log_path =&gt; &quot;/Users/squareyun/Documents/utility/logstash-8.1.1/config/test.log&quot; sincedb_path =&gt; &quot;/dev/null&quot; } } output { stdout { } } . Reference . https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html#plugins-inputs-file-mode | .",
            "url": "https://knu-cd2.github.io/blog/logstash/2022/05/06/logstash-file-input-plugin-just-one-line.html",
            "relUrl": "/logstash/2022/05/06/logstash-file-input-plugin-just-one-line.html",
            "date": " • May 6, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "On-premise hardware setting",
            "content": "온프레미스 환경에 사용된 장비 및 부품 . 1. 라즈베리파이 4B 8GB . . 2. 라즈베리파이 4B 4GB . . 3. 디스크 - 32GB MLC . . 4. 공유기 - iptime A3004T . . 5. 스위칭 허브 - iptime H6008 . . 그 외 부품들 . - cat6 30cm 랜선 - 5V 3A 충전기 - 아크릴 케이스 홀더 박스 - 5V 0.2A 냉각팬 .",
            "url": "https://knu-cd2.github.io/blog/on-premise/2022/05/05/on-premise-hardware.html",
            "relUrl": "/on-premise/2022/05/05/on-premise-hardware.html",
            "date": " • May 5, 2022"
        }
        
    
  
    
        ,"post16": {
            "title": "How to deploy a multi-node elasticsearch cluster",
            "content": "엘라스틱서치 다중노드 클러스터 환경 구축 . 1. 인증서 생성 . 클러스터에 포함된 노드들은 서로 transport module을 이용하여 통신을 한다. 통신을 할 때 보안을 위해 TLS를 사용하는데 이를 위해 인증서를 생성하자. . . 이 프로젝트에서는 서로 다른 2개의 서버에서 각각 노드 하나씩 생성하여 클러스터를 구성할 것이다. 첫번째 서버에서 인증서를 생성하고 이 인증서를 각 서버에 복사하는 과정을 진행할 것이다. 작동중인 elasticsearch는 모두 종료하고 진행한다. . CA를 생성한다. filename은 default인 elastic-stack-ca.p12로 진행한다. . ./bin/elasticsearch-certutil ca . 이 CA를 이용해 certificate and private key를 생성한다. filename은 default인 elastic-certificates.p12로 하고, 비밀번호는 기억해둔다. . ./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 . 생성된 elastic-certificates.p12를 config 폴더 안에 certs 폴더를 생성하고 거기에 복사한다. 그리고, 이 파일을 각 서버에 전송하여야 한다. (서버에도 certs 폴더를 생성해야함) linux의 scp 명령어를 이용해 파일을 전송하자. . scp -P {포트번호} /home/{저장 경로}/elasticsearch-8.1.0/config/certs/elastic-certificates.p12 {호스트 이름}@{공개 서버 주소}:/home/c2-elastic/elastic/elasticsearch-8.1.0/config/certs/ . 2. elasticsearch.yml 파일 설정 . 다음과 같이 elasticsearch.yml 파일을 각 서버마다 작성한다. 주석처리 되어있는 것을 해제하여 사용하여도 좋고, 첫 줄에 추가적으로 작성하여도 된다. 노드 이름은 각 서버마다 다르게 지정하여야 한다. . cluster.name: csp-cluster # 동일하기 node.name: c1-elastic # 서버마다 다르게 network.host: [&quot;_local_&quot;, &quot;_site_&quot;] http.port: 9200 # 클러스터에 포함된 노드의 서버 주소. 주의: public IP가 아닌 private IP를 작성한다. # hostname -I 명령어로 private IP 확인 가능함 discovery.seed_hosts: [&quot;192.168.0.6&quot;, &quot;192.168.0.14&quot;] cluster.initial_master_nodes: [&quot;c1-elastic&quot;, &quot;c2-elastic&quot;] # 클러스터에 포함된 노드의 이름 xpack.security.enabled: true xpack.security.enrollment.enabled: true xpack.security.transport.ssl: enabled: true verification_mode: certificate client_authentication: required keystore.path: certs/elastic-certificates.p12 truststore.path: certs/elastic-certificates.p12 transport.host: [_local_, _site_] # 이것은 첫번째 서버에서만 작성하면 됨 . 3. keystore에 비밀번호 저장 . 다음 명령어로 Elasticsearch keystore에 비밀번호를 저장한다. 각 서버마다 실행한다. . ./bin/elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password ./bin/elasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password . 4. HTTP 인증서 생성 . 첫번째 서버에서 다음 명령어로 Elasticsearch HTTP certificate를 생성한다. . ./bin/elasticsearch-certutil http . Generate a CSR? N | Use an existing CA? y | CA Path: /home/c2-elastic/elastic/elasticsearch-8.1.0/elastic-stack-ca.p12 | For how long should your certificate be valid?: 5y | Generate a certificate per node? n | Enter all the hostnames that you need: ubuntu (hostname 명령어로 확인 가능) | Enter all IP addresses that you need: 192.168.0.6 192.168.0.14 (private IP 작성) | Do you wish to change any of these options? n | 생성된 elasticsearch-ssl-http.zip 파일을 압축해제 하면 elasticsearch 폴더와 kibana 폴더가 생성된다. elasticsearch 폴더 내의 http.p12 파일은 config/certs 폴더에 이동하고, 이 파일을 각 서버에 전송한다. (scp 명령어 활용) kibana 폴더 내의 elasticsearch-ca.pem 파일은 키바나 폴더의 config/certs 폴더에 이동한다. . elasticsearch.yml 파일에 다음을 추가한다. . xpack.security.http.ssl: enabled: true keystore.path: certs/http.p12 . 4. keystore에 비밀번호 저장 . 다음 명령어로 Elasticsearch keystore에 비밀번호를 저장한다. 각 서버마다 실행한다. . ./bin/elasticsearch-keystore add xpack.security.http.ssl.keystore.secure_password . 5. kibana.yml 파일 설정 . 키바나를 실행시킬 서버에서 다음과 같이 yml 파일을 설정한다. . server.host: 0.0.0.0 server.publicBaseUrl: &quot;http://192.168.0.6:5601&quot; server.name: &quot;csp-kibana&quot; elasticsearch.hosts: [&quot;https://192.168.0.6:9200&quot;, &quot;https://192.168.0.14:9200&quot;] elasticsearch.ssl.certificateAuthorities: [&quot;/home/c1-elastic/elastic/kibana-8.1.0/config/certs/elasticsearch-ca.pem&quot;] elasticsearch.serviceAccountToken: # 초기 셋팅시 자동으로 생성된 서비스 토큰값 작성 . Reference . https://www.elastic.co/guide/en/elasticsearch/reference/8.1/security-basic-setup.html#encrypt-internode-communication | https://www.elastic.co/guide/en/elasticsearch/reference/8.1/security-basic-setup-https.html#encrypt-kibana-http | https://www.youtube.com/watch?v=id8L4fiCnQE&amp;t=939s | .",
            "url": "https://knu-cd2.github.io/blog/elasticsearch/2022/04/30/deploy-multinode-elasticsearch-cluster.html",
            "relUrl": "/elasticsearch/2022/04/30/deploy-multinode-elasticsearch-cluster.html",
            "date": " • Apr 30, 2022"
        }
        
    
  
    
        ,"post17": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://knu-cd2.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post18": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://knu-cd2.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://knu-cd2.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  
  

  

  
  

  
  

  

}